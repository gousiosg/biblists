%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for ??????? ??????? at 2006-05-28 23:57:38 +0300 


%% Saved with string encoding Western (ASCII) 



@article{Bull03,
	Abstract = {Increasing interest is being shown in the use of Java for scientific applications. The Java Grande benchmark suite was designed with such applications primarily in mind. The perceived lack of performance of Java still deters many potential users, despite recent advances in just-in-time and adaptive compilers. There are, however, few benchmark results available comparing Java to more traditional languages such as C and Fortran. To address this issue, a subset of the Java Grande benchmarks has been re-written in C and Fortran allowing direct performance comparisons between the three languages. The performance of a range of Java execution environments, C and Fortran compilers have been tested across a number of platforms using the suite. These demonstrate that on some platforms (notable Intel Pentium) the performance gap is now quite small.},
	Author = {J. M. Bull and L. A. Smith and C. Ball and L. Pottage and R. Freeman},
	Date-Added = {2006-05-25 11:54:13 +0300},
	Date-Modified = {2006-05-28 23:57:38 +0300},
	Journal = {Concurrency and Computation: Practice and Experience},
	Month = {Feb},
	Number = {3--5},
	Pages = {417--430},
	Title = {Benchmarking {J}ava against {C} and {F}ortran for scientific applications},
	Volume = {15},
	Year = {2003}}

@techreport{Bartl88,
	Author = {Bartlett, Joel F.},
	Comment = {Excellent trick here---make newness a page property, not an address-range property},
	Date-Modified = {2005-11-29 15:00:40 +0200},
	Institution = {DEC Western Research Laboratory, Palo Alto, CA},
	Note = {Also in Lisp Pointers 1, 6 (April--June 1988), 2--12},
	Number = {88/2},
	Title = {Compacting Garbage Collection with Ambiguous Roots},
	Url = {http://www.research.digital.com/wrl/techreports/88.2.ps},
	Year = {1988}}

@inproceedings{Spoon05,
	Abstract = {We introduce an extension of mostly copying collection that uses page residency to determine when to relocate objects. Our collector promotes pages with high residency in place, avoiding unnecessary work and wasted space. It predicts the residency of each page, but when its predictions prove to be inaccurate, our collector reclaims unoccupied space by using it to satisfy allocation requests.Using residency allows our collector to dynamically balance the tradeoffs of copying and non-copying collection. Our technique requires less space than a pure copying collector and supports object pinning without otherwise sacrificing the ability to relocate objects.Unlike other hybrids, our collector does not depend on application-specific configuration and can quickly respond to changing application behavior. Our measurements show that our hybrid performs well under a variety of conditions; it prefers copying collection when there is ample heap space but falls back on non-copying collection when space becomes limited.},
	Address = {New York, NY, USA},
	Author = {Daniel Spoonhower and Guy Blelloch and Robert Harper},
	Booktitle = {VEE '05: Proceedings of the 1st ACM/USENIX international conference on Virtual execution environments},
	Date-Added = {2005-11-07 15:34:13 +0200},
	Date-Modified = {2005-11-07 15:35:04 +0200},
	Doi = {http://doi.acm.org/10.1145/1064979.1064989},
	Isbn = {1-59593-047-7},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/GarbageCollection/Using%20page%20residency%20to%20balance%20tradeoffs%20in%20tracing%20garbage%20collection.pdf},
	Location = {Chicago, IL, USA},
	Pages = {57--67},
	Publisher = {ACM Press},
	Title = {Using page residency to balance tradeoffs in tracing garbage collection},
	Year = {2005}}

@inproceedings{Moon84,
	Address = {New York, NY, USA},
	Author = {David A. Moon},
	Booktitle = {LFP '84: Proceedings of the 1984 ACM Symposium on LISP and functional programming},
	Date-Added = {2005-10-05 12:22:41 +0300},
	Date-Modified = {2005-11-07 14:45:36 +0200},
	Isbn = {0-89791-142-3},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Garbage%20Collection%20in%20a%20Large%20Lisp%20System%20.pdf},
	Location = {Austin, Texas, United States},
	Pages = {235--246},
	Publisher = {ACM Press},
	Title = {Garbage collection in a large LISP system},
	Year = {1984}}

@inproceedings{Appel91,
	Address = {New York, NY, USA},
	Author = {Andrew W. Appel and Kai Li},
	Booktitle = {ASPLOS-IV: Proceedings of the fourth international conference on Architectural support for programming languages and operating systems},
	Date-Added = {2005-10-05 12:31:21 +0300},
	Date-Modified = {2005-11-07 14:46:13 +0200},
	Doi = {http://doi.acm.org/10.1145/106972.106984},
	Isbn = {0-89791-380-9},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Virtual%20Memory%20Primitives%20for%20User%20Programs%20.pdf},
	Location = {Santa Clara, California, United States},
	Pages = {96--107},
	Publisher = {ACM Press},
	Title = {Virtual memory primitives for user programs},
	Year = {1991}}

@inproceedings{Coope92,
	Address = {New York, NY, USA},
	Author = {Eric Cooper and Scott Nettles and Indira Subramanian},
	Booktitle = {LFP '92: Proceedings of the 1992 ACM conference on LISP and functional programming},
	Date-Added = {2005-10-05 12:25:02 +0300},
	Date-Modified = {2005-11-07 14:46:53 +0200},
	Doi = {http://doi.acm.org/10.1145/141471.141501},
	Isbn = {0-89791-481-3},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Improving%20the%20performance%20of%20SML%20garbage%20collection%20using%20application-specific%20virtual%20memory%20management.pdf},
	Location = {San Francisco, California, United States},
	Pages = {43--52},
	Publisher = {ACM Press},
	Title = {Improving the performance of SML garbage collection using application-specific virtual memory management},
	Year = {1992}}

@article{Detle94,
	Author = {David Detlefs and Al Dosser and Benjamin Zorn},
	Date-Modified = {2005-11-07 14:53:49 +0200},
	Institution = {Digital Equipment Corporation and University of Colorado},
	Journal = {Software Practice and Experience},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Memory%20Allocation%20Costs%20in%20Large%20C%20and%20C++%20Programs.pdf},
	Number = {6},
	Publisher = {Wiley},
	Title = {Memory Allocation Costs in Large {C} and {C++} Programs},
	Volume = {24},
	Year = {1994}}

@article{Rodri97,
	Abstract = {It is well accepted that automatic garbage collection
simplifies programming, promotes modularity, and reduces development
effort. However it is commonly believed that these advantages do not
counteract the perceived price: excessive overheads, possible long
pause times while garbage collections occur, and the need to modify
existing code. Even though there are publically available garbage
collector implementations that can be used in existing programs, they
do not guarantee short pauses, and some modification of the application
using them is still required. In this paper we describe a
snapshot-at-beginning concurrent garbage collector algorithm and its
implementation. This algorithm guarantees short pauses, and can be
easily implemented on stock UNIX-like operating systems. Our results
show that our collector performs comparable to other garbage collection
implementations on uniprocessor machines and outperforms similar
collectors on multiprocessor machines. We also show our collector to be
competitive in performance with explicit deallocation. Our collector
has the added advantage of being non-intrusive. Using a dynamic linking
technique and effective root set inferencing, we have been able to
successfully run our collector even in commercial programs where only
the binary executable and no source code is available. In this paper we
describe our algorithm, its implementation, and provide both an
algorithmic and a performance comparison between our collector and
other similar garbage collectors.},
	Annote = {-Good description of the advantages of using GC over explicit deallocation
-Explains write barriers implemented in the OS VM
-Explains the workings of the Boehm-Weiser conservative collector},
	Author = {Gustavo Rodriguez-Rivera and Vince Russo},
	Date-Added = {2005-10-11 15:34:40 +0300},
	Date-Modified = {2005-11-07 14:54:18 +0200},
	Journal = {Software Practice and Experience},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Nonintrusive%20Cloning%20Garbage%20Collection%20with%20Stock%20Operating%20System%20Support.pdf},
	Number = {8},
	Title = {Non-intrusive Cloning Garbage Collection with Stock Operating System Support},
	Volume = {27},
	Year = {1997}}

@inproceedings{Halle02,
	Abstract = {This paper describes a memory discipline that combines region-based memory management and copying garbage collection by extending Cheney's copying garbage collection algorithm to work with regions. The paper presents empirical evidence that region inference very significantly reduces the number of garbage collections; and evidence that the fastest execution is obtained by using regions alone, without garbage collection. The memory discipline is implemented for Standard ML in the ML Kit compiler and measurements show that for a variety of benchmark programs, code generated by the compiler is as efficient, both with respect to execution time and memory usage, as programs compiled with Standard ML of New Jersey, another state-of-the-art Standard ML compiler.},
	Address = {New York, NY, USA},
	Author = {Niels Hallenberg and Martin Elsman and Mads Tofte},
	Booktitle = {PLDI '02: Proceedings of the ACM SIGPLAN 2002 Conference on Programming language design and implementation},
	Date-Added = {2005-11-07 14:39:13 +0200},
	Date-Modified = {2006-05-02 13:41:10 +0300},
	Doi = {http://doi.acm.org/10.1145/512529.512547},
	Isbn = {1-58113-463-0},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Combining%20Region%20Inference%20and%20Garbage%20Collection.pdf},
	Location = {Berlin, Germany},
	Pages = {141--152},
	Publisher = {ACM Press},
	Title = {Combining region inference and garbage collection},
	Year = {2002}}

@inproceedings{Yang04,
	Address = {New York, NY, USA},
	Author = {Ting Yang and Matthew Hertz and Emery D. Berger and Scott F. Kaplan and J. Eliot B. Moss},
	Booktitle = {ISMM '04: Proceedings of the 4th international symposium on Memory management},
	Date-Added = {2005-10-05 12:28:03 +0300},
	Date-Modified = {2005-11-07 14:55:42 +0200},
	Doi = {http://doi.acm.org/10.1145/1029873.1029881},
	Isbn = {1-58113-945-4},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Automatic%20Heap%20Sizing-%20Taking%20Real%20Memory%20Into%20Account%20.pdf},
	Location = {Vancouver, BC, Canada},
	Pages = {61--72},
	Publisher = {ACM Press},
	Title = {Automatic heap sizing: taking real memory into account},
	Year = {2004}}

@inproceedings{Soman04,
	Abstract = {Much prior work has shown that the performance enabled by garbage collection (GC) systems is highly dependent upon the behavior of the application as well as on the available resources. That is, no single GC enables the best performance for all programs and all heap sizes. To address this limitation, we present the design, implementation, and empirical evaluation of a novel Java Virtual Machine (JVM) extension that facilitates dynamic switching between a number of very different and popular garbage collectors. We also show how to exploit this functionality using annotation-guided GC selection and evaluate the system using a large number of benchmarks. In addition, we implement and evaluate a simple heuristic to investigate the efficacy of switching automatically. Our results show that, on average, our annotation-guided system introduces less than 4% overhead and improves performance by 24% over the worst-performing GC (across heap sizes) and by 7% over always using the popular Generational/Mark-Sweep hybrid.},
	Address = {New York, NY, USA},
	Author = {Sunil Soman and Chandra Krintz and David F. Bacon},
	Booktitle = {ISMM '04: Proceedings of the 4th international symposium on Memory management},
	Date-Added = {2005-11-07 14:32:05 +0200},
	Date-Modified = {2005-11-07 14:55:05 +0200},
	Doi = {http://doi.acm.org/10.1145/1029873.1029880},
	Isbn = {1-58113-945-4},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Dynamic%20selection%20of%20application-specific%20garbage%20collectors.pdf},
	Location = {Vancouver, BC, Canada},
	Pages = {49--60},
	Publisher = {ACM Press},
	Title = {Dynamic selection of application-specific garbage collectors},
	Year = {2004}}

@inproceedings{Hertz05a,
	Abstract = {Garbage collection yields numerous software engineering benefits, but its quantitative impact on performance remains elusive. One can compare the cost of conservative garbage collection to explicit memory management in C/C++ programs by linking in an appropriate collector. This kind of direct comparison is not possible for languages designed for garbage collection (e.g., Java), because programs in these languages naturally do not contain calls to free. Thus, the actual gap between the time and space performance of explicit memory management and precise, copying garbage collection remains unknown.We introduce a novel experimental methodology that lets us quantify the performance of precise garbage collection versus explicit memory management. Our system allows us to treat unaltered Java programs as if they used explicit memory management by relying on oracles to insert calls to free. These oracles are generated from profile information gathered in earlier application runs. By executing inside an architecturally-detailed simulator, this "oracular" memory manager eliminates the effects of consulting an oracle while measuring the costs of calling malloc and free. We evaluate two different oracles: a liveness-based oracle that aggressively frees objects immediately after their last use, and a reachability-based oracle that conservatively frees objects just after they are last reachable. These oracles span the range of possible placement of explicit deallocation calls.We compare explicit memory management to both copying and non-copying garbage collectors across a range of benchmarks using the oracular memory manager, and present real (non-simulated) runs that lend further validity to our results. These results quantify the time-space tradeoff of garbage collection: with five times as much memory, an Appel-style generational collector with a non-copying mature space matches the performance of reachability-based explicit memory management. With only three times as much memory, the collector runs on average 17% slower than explicit memory management. However, with only twice as much memory, garbage collection degrades performance by nearly 70%. When physical memory is scarce, paging causes garbage collection to run an order of magnitude slower than explicit memory management.},
	Address = {New York, NY, USA},
	Author = {Matthew Hertz and Emery D. Berger},
	Booktitle = {OOPSLA '05: Proceedings of the 20th annual ACM SIGPLAN conference on Object oriented programming systems languages and applications},
	Date-Added = {2005-10-18 14:00:43 +0300},
	Date-Modified = {2005-11-07 14:56:38 +0200},
	Doi = {http://doi.acm.org/10.1145/1094811.1094836},
	Isbn = {1-59593-031-0},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Quantifying%20the%20Performance%20of%20Garbage%20Collection%20vs.%20Explicit%20Memory%20Management%20.pdf},
	Location = {San Diego, CA, USA},
	Pages = {313--326},
	Publisher = {ACM Press},
	Title = {Quantifying the performance of garbage collection vs. explicit memory management},
	Year = {2005}}

@inproceedings{Hertz05,
	Abstract = {Garbage collection offers numerous software engineering advantages, but interacts poorly with virtual memory managers. Existing garbage collectors require far more pages than the application's working set and touch pages without regard to which ones are in memory, especially during full-heap garbage collection. The resulting paging can cause throughput to plummet and pause times to spike up to seconds or even minutes. We present a garbage collector that avoids paging. This bookmarking collector cooperates with the virtual memory manager to guide its eviction decisions. Using summary information ("bookmarks") recorded from evicted pages, the collector can perform in-memory full-heap collections. In the absence of memory pressure, the bookmarking collector matches the throughput of the best collector we tested while running in smaller heaps. In the face of memory pressure, it improves throughput by up to a factor of five and reduces pause times by up to a factor of 45 over the next best collector. Compared to a collector that consistently provides high throughput (generational mark-sweep), the bookmarking collector reduces pause times by up to 218x and improves throughput by up to 41x. Bookmarking collection thus provides greater utilization of available physical memory than other collectors while matching or exceeding their throughput.},
	Address = {New York, NY, USA},
	Author = {Matthew Hertz and Yi Feng and Emery D. Berger},
	Booktitle = {PLDI '05: Proceedings of the 2005 ACM SIGPLAN conference on Programming language design and implementation},
	Date-Added = {2005-10-03 13:35:17 +0300},
	Date-Modified = {2005-11-07 14:56:56 +0200},
	Doi = {http://doi.acm.org/10.1145/1065010.1065028},
	Isbn = {1-59593-056-6},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Garbage%20collection%20without%20paging.pdf},
	Location = {Chicago, IL, USA},
	Pages = {143--153},
	Publisher = {ACM Press},
	Title = {Garbage collection without paging},
	Year = {2005}}

@techreport{JRock03,
	Date-Added = {2005-11-06 22:23:44 +0200},
	Date-Modified = {2005-11-06 22:23:44 +0200},
	Institution = {BEA Systems},
	Title = {{BEA} {W}eblogic {JR}ockit: {J}ava for the enterprise},
	Url = {http://www.bea.com/content/news_events/white_papers/BEA_JRockit_wp.pdf},
	Year = {2003}}

@techreport{JRock04,
	Date-Added = {2005-11-06 22:23:44 +0200},
	Date-Modified = {2005-11-06 22:23:44 +0200},
	Institution = {BEA Systems},
	Title = {Using the {BEA JR}ockit Memory Management System},
	Url = {http://e-docs.bea.com/wljrockit/docs142/userguide/memman.html},
	Year = {2004}}

@techreport{IBM05,
	Address = {http://www-128.ibm.com/developerworks/java/jdk/diagnosis/},
	Date-Added = {2005-11-06 22:23:12 +0200},
	Date-Modified = {2005-11-06 22:23:12 +0200},
	Institution = {IBM},
	Title = {{IBM JVM} Garbage Collection and Storage Allocation Techniques},
	Year = {2005}}

@techreport{Chawl03,
	Address = {http://www-128.ibm.com/developerworks/library/i-gctroub/},
	Author = {Sumit Chawla},
	Date-Added = {2005-11-06 22:22:51 +0200},
	Date-Modified = {2005-11-06 22:22:51 +0200},
	Institution = {IBM},
	Title = {Fine-tuning {J}ava garbage collection performance},
	Year = {2003}}

@techreport{Aruna03,
	Address = {http://www-128.ibm.com/developerworks/ibm/library/i-incrcomp/},
	Author = {Aruna Kalagnanam, Sripathi Kodi},
	Date-Added = {2005-11-06 22:22:51 +0200},
	Date-Modified = {2005-11-06 22:22:51 +0200},
	Institution = {IBM},
	Title = {Mash the trash -- Incremental compaction in the {IBM JDK} garbage collector},
	Year = {2003}}

@techreport{Sun05,
	Abstract = {The JavaTM 2 Platform Standard Edition (J2SETM platform) is used for a wide variety of applications from small applets on desktops to web services on large servers. In the J2SE platform version 1.4.2 there were four garbage collectors from which to choose but without an explicit choice by the user the serial garbage collector was always chosen. In version 5.0 the choice of the collector is based on the class of the machine on which the application is started.

This ``smarter choice'' of the garbage collector is generally better but is not always the best. For the user who wants to make their own choice of garbage collectors, this document will provide information on which to base that choice. This will first include the general features of the garbage collections and tuning options to take the best advantage of those features. The examples are given in the context of the serial, stop-the-world collector. Then specific features of the other collectors will be discussed along with factors that should considered when choosing one of the other collectors.},
	Date-Added = {2005-11-06 22:21:29 +0200},
	Date-Modified = {2005-11-06 22:21:29 +0200},
	Institution = {Sun Microsystems, Inc},
	Title = {Tuning Garbage Collection with the 5.0 {J}ava Virtual Machine},
	Url = {http://java.sun.com/docs/hotspot/gc5.0/gc_tuning_5.html},
	Year = {2005}}

@article{Liebe83,
	Abstract = {In previous heap storage systems, the cost of creating objects and garbage collection is independent of the lifetime of the object. Since objects with short lifetimes account for a large portion of storage use, it is worth optimizing a garbage collector to reclaim storage for these objects more quickly. The garbage collector should spend proportionately less effort reclaiming objects with longer lifetimes. We present a garbage collection algorithm that (1) makes storage for short-lived objects cheaper than storage for long-lived objects, (2) that operates in real time---object creation and access times are bounded, (3) increases locality of reference, for better virtual memory performance, (4) works well with multiple processors and a large address space.},
	Address = {New York, NY, USA},
	Author = {Henry Lieberman and Carl Hewitt},
	Date-Added = {2005-06-28 17:43:22 +0300},
	Date-Modified = {2005-06-28 17:46:06 +0300},
	Doi = {http://doi.acm.org/10.1145/358141.358147},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20real-time%20garbage%20collector%20based%20on%20the%20lifetimes%20of%20objects.pdf},
	Number = {6},
	Pages = {419--429},
	Publisher = {ACM Press},
	Title = {A real-time garbage collector based on the lifetimes of objects},
	Volume = {26},
	Year = {1983}}

@inproceedings{Holzl93,
	Address = {Washington, D.C},
	Author = {Urs Holzle},
	Booktitle = {OOPSLA'93 Garbage Collection Workshop},
	Date-Added = {2005-06-28 16:11:15 +0300},
	Date-Modified = {2005-06-28 16:15:07 +0300},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20Fast%20Write%20Barrier%20for%20Generational%20Garbage%20Collectors.pdf},
	Month = {Oct},
	Title = {A Fast Write Barrier for Generational Garbage Collectors},
	Year = {1993}}

@inproceedings{Print00,
	Abstract = {This paper reports our experiences with a mostly-concurrent incremental garbage collector, implemented in the context of a high performance virtual machine for the Java programming language. The garbage collector is based on the ``mostly parallel'' collection algorithm of Boehm et al. and can be used as the old generation of a generational memory system. It overloads efficient write-barrier code already generated to support generational garbage collection to also identify objects that were modified during concurrent marking. These objects must be rescanned to ensure that the concurrent marking phase marks all live objects. This algorithm minimises maximum garbage collection pause times, while having only a small impact on the average garbage collection pause time and overall execution time. We support our claims with experimental results, for both a synthetic benchmark and real programs.},
	Address = {New York, NY, USA},
	Author = {Tony Printezis and David Detlefs},
	Booktitle = {ISMM '00: Proceedings of the 2nd international symposium on Memory management},
	Date-Added = {2005-06-28 16:06:44 +0300},
	Date-Modified = {2005-06-28 16:08:16 +0300},
	Doi = {http://doi.acm.org/10.1145/362422.362480},
	Isbn = {1-58113-263-8},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20generational%20mostly-concurrent%20garbage%20collector.pdf},
	Location = {Minneapolis, Minnesota, United States},
	Pages = {143--154},
	Publisher = {ACM Press},
	Title = {A generational mostly-concurrent garbage collector},
	Year = {2000}}

@inproceedings{Zee02,
	Abstract = {We present a new analysis for removing unnecessary write barriers in programs that use generational garbage collection. To our knowledge, this is the first static program analysis for this purpose. Our algorithm uses a pointer analysis to locate assignments that always create a reference from a younger object to an older object, then transforms the program to remove the write barriers normally associated with such assignments. We have implemented two transformations that reorder object allocations; these transformations can significantly increase the effectiveness of our write barrier removal algorithm.Our base technique assumes that the collector promotes objects in age order. We have developed an extension that enables the optimistic removal of write barriers, with the collector lazily adding each newly promoted object into a remembered set of objects whenever the compiler may have removed write barriers involving the object at statements that have yet to execute. This mechanism enables the application of our technique to virtually any memory management system that uses write barriers to enable generational garbage collection.Results from our implemented system show that our technique can remove substantial numbers of write barriers from the majority of the programs in our benchmark set, producing modest performance improvements of up to 6% of the overall execution time. Moreover, by dynamically instrumenting the executable, we are able to show that for six of our nine benchmark programs, our analysis is close to optimal in the sense that it removes the write barriers for almost all assignments that do not, in the observed execution, create a reference from an older object to a younger object. Finally, our results show that the overhead of our optimistic extension is negligible.},
	Address = {New York, NY, USA},
	Author = {Karen Zee and Martin Rinard},
	Booktitle = {OOPSLA '02: Proceedings of the 17th ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
	Date-Added = {2005-06-28 16:03:15 +0300},
	Date-Modified = {2005-06-28 16:03:51 +0300},
	Doi = {http://doi.acm.org/10.1145/582419.582439},
	Isbn = {1-58113-471-1},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Write%20Barrier%20Removal%20by%20Static%20Analysis.pdf},
	Location = {Seattle, Washington, USA},
	Pages = {191--210},
	Publisher = {ACM Press},
	Title = {Write barrier removal by static analysis},
	Year = {2002}}

@inproceedings{Veche04,
	Abstract = {Concurrent garbage collectors require write barriers to preserve consistency, but these barriers impose significant direct and indirect costs. While there has been a lot of work on optimizing write barriers, we present the first study of their elision in a concurrent collector. We show conditions under which write barriers are redundant, and describe how these conditions can be applied to both incremental update or snapshot-at-the-beginning barriers. We then evaluate the potential for write barrier elimination with a trace-based limit study, which shows that a significant percentage of write barriers are redundant. On average, 54% of incremental barriers and 83% of snapshot barriers are unnecessary.},
	Address = {New York, NY, USA},
	Author = {Martin T. Vechev and David F. Bacon},
	Booktitle = {ISMM '04: Proceedings of the 4th international symposium on Memory management},
	Date-Added = {2005-06-28 15:39:17 +0300},
	Date-Modified = {2005-06-28 15:59:40 +0300},
	Doi = {http://doi.acm.org/10.1145/1029873.1029876},
	Isbn = {1-58113-945-4},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Write%20barrier%20elision%20for%20concurrent%20garbage%20collectors.pdf},
	Location = {Vancouver, BC, Canada},
	Pages = {13--24},
	Publisher = {ACM Press},
	Title = {Write barrier elision for concurrent garbage collectors},
	Year = {2004}}

@inproceedings{Black02,
	Abstract = {In many garbage collected systems, the mutator performs a write barrier for every pointer update. Using generational garbage collectors, we study in depth three code placement options for remembered-set write barriers: inlined, out-of-line, and partially inlined (fast path inlined, slow path out-of-line). The fast path determines if the collector needs to remember thepointer update. The slow path records the pointer in a list when necessary. Efficient implementations minimize the instructions on the fast path, and record few pointers (from 0.16 to 3% of pointer stores in our benchmarks). We find the mutator performs best with a partially inlined barrier, by a modest 1.5% on average over full inlining.We also study the compilation cost of write-barrier code placement. We find that partial inlining reduces the compilation cost by 20 to 25% compared to full inlining. In the context of just-in-time compilation, the application is exposed to compiler activity. Regardless of the level of compiler activity, partial inlining consistently gives a total running time performance advantage over full inlining on the benchmarks. When the compiler optimizes all application methods on demand and compiler load is highest, partial inlining improves total performance on average by 10.2%, and up to 18.5%.},
	Address = {New York, NY, USA},
	Author = {Stephen M Blackburn and Kathryn S. McKinley},
	Booktitle = {ISMM '02: Proceedings of the 3rd international symposium on Memory management},
	Date-Added = {2005-06-28 15:35:34 +0300},
	Date-Modified = {2005-06-28 15:38:31 +0300},
	Doi = {http://doi.acm.org/10.1145/512429.512452},
	Isbn = {1-58113-539-4},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/In%20or%20out%20-%20putting%20write%20barriers%20in%20their%20place.pdf},
	Location = {Berlin, Germany},
	Pages = {175--184},
	Publisher = {ACM Press},
	Title = {In or out?: putting write barriers in their place},
	Year = {2002}}

@inproceedings{Stefa99,
	Abstract = {Modern generational garbage collectors look for garbage among the young objects, because they have high mortality; however, these objects include the very youngest objects, which clearly are still live. We introduce new garbage collection algorithms, called age-based, some of which postpone consideration of the youngest objects. Collecting less than the whole heap requires write barrier mechanisms to track pointers into the collected region. We describe here a new, efficient write barrier implementation that works for age-based and traditional generational collectors. To compare several collectors, their configurations, and program behavior, we use an accurate simulator that models all heap objects and the pointers among them, but does not model cache or other memory effects. For object-oriented languages, our results demonstrate that an older-first collector, which collects older objects before the youngest ones, copies on average much less data than generational collectors. Our results also show that an older-first collector does track more pointers, but the combined cost of copying and pointer tracking still favors an older-first over a generational collector in many cases. More importantly, we reopen for consideration the question where in the heap and with which policies copying collectors will achieve their best performance.},
	Address = {New York, NY, USA},
	Author = {Darko Stefanovi\&\#263; and Kathryn S. McKinley and J. Eliot B. Moss},
	Booktitle = {OOPSLA '99: Proceedings of the 14th ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
	Date-Added = {2005-06-28 15:15:41 +0300},
	Date-Modified = {2005-06-28 15:16:02 +0300},
	Doi = {http://doi.acm.org/10.1145/320384.320425},
	Isbn = {1-58113-238-7},
	Location = {Denver, Colorado, United States},
	Pages = {370--381},
	Publisher = {ACM Press},
	Title = {Age-based garbage collection},
	Year = {1999}}

@inproceedings{Barre93,
	Address = {New York, NY, USA},
	Author = {David A. Barrett and Benjamin G. Zorn},
	Booktitle = {PLDI '93: Proceedings of the ACM SIGPLAN 1993 conference on Programming language design and implementation},
	Date-Added = {2005-06-22 17:18:52 +0300},
	Date-Modified = {2005-06-22 17:21:07 +0300},
	Doi = {http://doi.acm.org/10.1145/155090.155108},
	Isbn = {0-89791-598-4},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Using%20lifetime%20predictors%20to%20improve%20memory%20allocation%20performance.pdf},
	Location = {Albuquerque, New Mexico, United States},
	Pages = {187--196},
	Publisher = {ACM Press},
	Title = {Using lifetime predictors to improve memory allocation performance},
	Year = {1993}}

@inproceedings{Hayes91,
	Address = {New York, NY, USA},
	Author = {Barry Hayes},
	Booktitle = {OOPSLA '91: Conference proceedings on Object-oriented programming systems, languages, and applications},
	Date-Added = {2005-06-22 16:33:32 +0300},
	Date-Modified = {2005-06-22 16:33:32 +0300},
	Doi = {http://doi.acm.org/10.1145/117954.117957},
	Isbn = {0-201-55417-8},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Using%20key%20object%20opportunism%20to%20collect%20old%20objects.pdf},
	Location = {Phoenix, Arizona, United States},
	Pages = {33--46},
	Publisher = {ACM Press},
	Title = {Using key object opportunism to collect old objects},
	Year = {1991}}

@article{Appel87,
	Abstract = {A very old and simple algorithm for garbage collection gives very good results 
when the physical memory is much larger than the number of reachable cells. In fact, the 
overhead associated with allocating and collecting cells from the heap can be reduced to less than one instruction per cell by increasing the size of physical memory. Special 
hardware, intricate garbage-collection algorithms, and fancy compiler analysis become 
unnecessary.},
	Address = {Amsterdam, The Netherlands, The Netherlands},
	Annote = {Appel argues that garbage collection using a simple copying collector and simple next-free allocation can be faster than explicit memory management and stack allocation given enough space. He presents both the mathematical calculations and an actual experiment to support his case.},
	Author = {Andrew W. Appel},
	Date-Modified = {2005-05-31 13:46:37 +0300},
	Doi = {http://dx.doi.org/10.1016/0020-0190(87)90175-X},
	Issn = {0020-0190},
	Journal = {Inf. Process. Lett.},
	Number = {4},
	Pages = {275--279},
	Publisher = {Elsevier North-Holland, Inc.},
	Title = {Garbage collection can be faster than stack allocation},
	Volume = {25},
	Year = {1987}}

@techreport{Minsk63,
	Address = {MIT, Cambridge, MA},
	Author = {Marvin L. Minsky},
	Comments = {Presents an algorithm which eliminates the difficulties of having a shared cell being output more than once to secondary storage. Does not use a stack, but requires one mark-bit per lisp cell. Live data is copied out to a file and then read back in. This algorithm is linearizing. Lisp 1.5. Would be unbearably slow on a modern machine.},
	Date-Modified = {2005-05-27 16:43:53 +0300},
	Institution = {Project MAC},
	Number = {Memo 58 (rev.)},
	Title = {A {L}isp Garbage Collector Algorithm Using Serial Secondary Storage},
	Year = {1963}}

@article{Fenic69,
	Abstract = {In this paper a garbage-collection algorithm for list-processing systems which operate within very large virtual memo, ies is described. The object of the algorithm is more the compaction of active storage than the discovery of free storage. Because free storage is never really exhausted, the decision to garbage collect is not easily madecision are discussed. },
	Address = {New York, NY, USA},
	Author = {Robert R. Fenichel and Jerome C. Yochelson},
	Date-Modified = {2005-05-27 16:28:59 +0300},
	Doi = {http://doi.acm.org/10.1145/363269.363280},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20LISP%20garbage-collector%20for%20virtual-memory%20computer%20systems.pdf},
	Number = {11},
	Pages = {611--612},
	Publisher = {ACM Press},
	Title = {A LISP garbage-collector for virtual-memory computer systems},
	Volume = {12},
	Year = {1969}}

@article{Jonke79,
	Abstract = { A compaction algorithm for variable size storage elements is described for use in a compacting garbage collector. Under certain plausible assumptions on the structure of these storage elements, the algorithm requires no space overhead and is faster than any compaction algorithm published to date. It scans the area to be compacted twice, but examines pointers only once.},
	Author = {H. B. M. Jonkers},
	Date-Modified = {2005-05-26 14:22:58 +0300},
	Journal = {Information Processing Letters},
	Number = {1},
	Pages = {25--30},
	Publisher = {North Holland},
	Title = {A Fast Garbage Compaction Algorithm},
	Volume = {9},
	Year = {1979}}

@article{Haddo67,
	Abstract = {When a dynamic storage allocation scheme requires variable-length elements, an element of a given length may be requested when no free element large enough is available. This can happen even though the total free space is more than adequate to fulfil the request. In such a situation the program will fail unless some method is at hand for forming the available space into a single element large enough to satisfy the request. We present a procedure for compacting the store such that all of the free space forms a single element.

},
	Author = {B.K. Haddon and W.M. Waite},
	Date-Added = {2005-05-26 14:13:20 +0300},
	Date-Modified = {2005-05-26 14:19:02 +0300},
	Journal = {Computer Journal},
	Number = {10},
	Pages = {162--165},
	Title = {A compaction procedure for variable length storage elements},
	Url = {http://www3.oup.co.uk/computer_journal/hdb/Volume_10/Issue_02/100162.sgm.abs.html},
	Year = {1967}}

@inbook{Knuth73,
	Address = {Reading, Mass},
	Author = {Donald E. Knuth},
	Chapter = {2},
	Commments = {section 2.3.5 is the most comprehensive description and analysis of algorithms that appeared prior to 1968. Standard reference for these algorithms before cohe81},
	Date-Modified = {2005-05-26 14:06:18 +0300},
	Edition = {Second},
	Publisher = {Addison-Wesley},
	Title = {The Art of Computer Programming},
	Volume = {I: Fundamental Algorithms},
	Year = {1973}}

@book{Jones96,
	Address = {Chichester},
	Author = {Richard E. Jones and Rafael Lins},
	Comment = {Reprinted February 1997, November 1997, January 1999, April 2000.},
	Date-Modified = {2005-05-24 13:56:55 +0300},
	Isbn = {0--471--94148--4},
	Note = {With a chapter on Distributed Garbage Collection by R. Lins.},
	Pages = {403},
	Publisher = {Wiley},
	Title = {Garbage Collection: Algorithms for Automatic Dynamic Memory Management},
	Url = {http://www.cs.ukc.ac.uk/people/staff/rej/gcbook/gcbook.html},
	Year = {1996}}

@article{Boehm88,
	Abstract = {We describe a technique for storage allocation and garbage collection in the absence of significant cooperation from the code using the allocator. This limits garbage collection overhead to the time actually required for garbage collection. In particular, application programs that rarely or never make use of the collector no longer encounter a substantial performance penalty. This approach greatly simplifies the implementation of languages supporting garbage collection. It further allows conventional compilers to be used with a garbage collector,either as the primary means of storage reclamation, or as a debugging tool. 
Our approach has two potential disadvantages. First, some garbage may fail to be reclaimed. Second, weuse a ``stop and collect'' approach, thus making the strategy unsuitable for applications with severe real-time constraints. We argue that the first problem is, to some extent, inherent in any garbage collection system. Furthermore, based on our experience, it is usually not significant in practice. In spite of the second problem, we have had favorable experiences with interactive applications, including some that use a heap of several megabytes. 
},
	Address = {New York, NY, USA},
	Author = {Hans-Juergen Boehm and Mark Weiser},
	Date-Modified = {2005-11-29 12:36:17 +0200},
	Issn = {0038-0644},
	Journal = {Softw. Pract. Exper.},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/GarbageCollection/Garbage%20collection%20in%20an%20uncooperative%20environment.pdf},
	Number = {9},
	Pages = {807--820},
	Publisher = {John Wiley \& Sons, Inc.},
	Title = {Garbage collection in an uncooperative environment},
	Volume = {18},
	Year = {1988}}

@article{McCar60,
	Abstract = {The attached paper is a description of the LISP system starting with the machine-independent system of recursive functions of symbolic expressions. This seems to be a better point of view for looking at the system than the original programming approach. After revision, the paper will be submitted for publication in a logic or computing journal. This memorandum contains only the machine independent parts of the system. The representation of S-expressions in the computer and the system for representing S-functions by computer subroutines will be added.},
	Address = {New York, NY, USA},
	Annote = {Describes, among a huge list of contibutions, the first automatic storage reclamation mechanism in its simplest form of a mark-sweep collector.},
	Author = {John McCarthy},
	Date-Modified = {2005-06-22 15:55:03 +0300},
	Doi = {http://doi.acm.org/10.1145/367177.367199},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Recursive%20functions%20of%20symbolic%20expressions%20and%20their%20computation%20by%20machine.pdf},
	Number = {4},
	Pages = {184--195},
	Publisher = {ACM Press},
	Title = {Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I},
	Volume = {3},
	Year = {1960}}

@inproceedings{Lins02,
	Abstract = {Weighted reference counting is a very simple and efficient memory management system for multiprocessor architectures. This paper extends the weighted reference counting algorithm to work efficiently with cyclic data structures.},
	Address = {Washington, DC, USA},
	Author = {R. Lins},
	Booktitle = {SBAC-PAD '02: Proceedings of the 14th Symposium on Computer Architecture and High Performance Computing (SCAB-PAD'02)},
	Date-Modified = {2005-05-20 15:27:28 +0300},
	Isbn = {0-7695-1772-2},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Efficient%20Cyclic%20Weighted%20Reference%20Counting.pdf},
	Pages = {61},
	Publisher = {IEEE Computer Society},
	Title = {Efficient Cyclic Weighted Reference Counting},
	Year = {2002}}

@techreport{DeTre90,
	Author = {John DeTreville},
	Comment = {Reference counting + mark-sweep. Reference counting may give better locality than other techniques (based on experience with the Topaz system).},
	Date-Modified = {2005-05-20 14:40:24 +0300},
	Institution = {DEC Systems Research Center, Palo Alto, CA},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Experience%20with%20Concurrent%20Garbage%20Collectors%20for%20Modula-2.pdf},
	Number = {64},
	Title = {Experience with Concurrent Garbage Collectors for {M}odula-2+},
	Year = {1990}}

@article{McBet63,
	Address = {New York, NY, USA},
	Annote = {Reference counting is unable to restore cyclic data structures},
	Author = {J. Harold McBeth},
	Date-Modified = {2005-05-20 12:00:24 +0300},
	Doi = {http://doi.acm.org/10.1145/367593.367649},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Number = {9},
	Pages = {575},
	Publisher = {ACM Press},
	Title = {Letters to the editor: on the reference counter method},
	Volume = {6},
	Year = {1963}}

@inproceedings{Ungar84,
	Abstract = {Many interactive computing environments provide automatic storage reclamation and virtual memory to ease the burden of managing storage. Unfortunately, many storage reclamation algorithms impede interaction with distracting pauses. Generation Scavenging is a reclamation algorithm that has no noticeable pauses, eliminates page faults for transient objects, compacts objects without resorting to indirection, and reclaims circular structures, in one third the time of traditional approaches. We have incorporated Generation Scavenging in Berkeley Smalltalk(BS), our Smalltalk-80 implementation, and instrumented it to obtain performance data. We are also designing a microprocessor with hardware support for Generation Scavenging.},
	Address = {New York, NY, USA},
	Author = {David Ungar},
	Booktitle = {SDE 1: Proceedings of the first ACM SIGSOFT/SIGPLAN software engineering symposium on Practical software development environments},
	Date-Modified = {2005-06-22 16:07:33 +0300},
	Doi = {http://doi.acm.org/10.1145/800020.808261},
	Isbn = {0-89791-131-8},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Generation%20Scavenging-%20A%20non-disruptive%20high%20performance%20storage%20reclamation%20algorithm.pdf},
	Pages = {157--167},
	Publisher = {ACM Press},
	Title = {Generation Scavenging: A non-disruptive high performance storage reclamation algorithm},
	Year = {1984}}

@techreport{Zorn90,
	Author = {Zorn, Benjamin},
	Date-Modified = {2005-04-25 11:54:59 +0300},
	Institution = {University of Colorado at Boulder},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Barrier%20Methods%20for%20Garbage%20Collection.pdf},
	Number = {CU-CS-494-90},
	Title = {Barrier Methods for Garbage Collection},
	Url = {http://www.cs.colorado.edu/department/publications/reports/docs/CU-CS-494-90.ps},
	Year = {1990}}

@inproceedings{Taylo86,
	Abstract = {The SPUR microprocessor has a 40-bit tagged architecture designed to improve its performance for Lisp programs. Although SPUR includes just a small set of enhancements to the Berkeley RISC-II architecture, simulation results show that with a 150-ns cycle time SPUR will run Common Lisp programs at least as fast as a Symbolies 3600 or a DEC VAX 8600. This paper explains SPUR's instruction set architecture and provides measurements of how certain components of the architecture perform.},
	Address = {Los Alamitos, CA, USA},
	Author = {G. S. Taylor and P. N. Hilfinger and J. R. Larus and D. A. Patterson and B. G. Zorn},
	Booktitle = {ISCA '86: Proceedings of the 13th annual international symposium on Computer architecture},
	Date-Modified = {2005-05-05 11:47:22 +0300},
	Doi = {http://doi.acm.org/10.1145/17407.17379},
	Isbn = {0-8186-0719-X},
	Location = {Tokyo, Japan},
	Pages = {444--452},
	Publisher = {IEEE Computer Society Press},
	Title = {Evaluation of the {SPUR L}isp architecture},
	Year = {1986}}

@article{Weize63,
	Abstract = {A list processing system in which each list cell contains both a forward and a backward link as well as a datum is described. This system is intended for imbedding in higher level languages capable of calling functions and subroutines coded in machine language. The presentation is in the form of FORTRAN programs depending on only a limited set of ``primitive'' machine language subroutines which are also defined. Finally, a set of field, particularly character, manipulation primitives are given to round out the system.},
	Address = {New York, NY, USA},
	Author = {J. Weizenbaum},
	Date-Modified = {2005-06-22 15:55:03 +0300},
	Doi = {http://doi.acm.org/10.1145/367593.367617},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Symmetric%20list%20processor.pdf},
	Number = {9},
	Pages = {524--536},
	Publisher = {ACM Press},
	Title = {Symmetric List Processor},
	Volume = {6},
	Year = {1963}}

@article{Weize69,
	Abstract = {One  consequence  of  the  reference-count-based  space-re-  covery system employed by SLIP is that reentrant list structures  are  not  recovered  even  when  explicitly  erased.  LISP-like  garbage-collection schemes are free of this impediment. They,  however, depend on being able to find  and  mark nodes that  are reachable from  program variables. By tracing all descend-  ants  of  such nodes  and  marking  them  as  well,  all  cells  not  reachable  from  program  variables  may  then  be  identified  and  collected. The  list-creating function  LIST of SLIP may  be  amended to mark those lists for which the programmer wishes  to  assume responsibility. Given  this  modification,  a  LISP-like  garbage  collector  that  recovers  abandoned  reentrant  list  structures may then be appended to the SLIP system.},
	Address = {New York, NY, USA},
	Author = {Joseph Weizenbaum},
	Date-Modified = {2005-05-05 11:57:53 +0300},
	Doi = {http://doi.acm.org/10.1145/363156.363159},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Recovery%20of%20reentrant%20list%20structures%20in%20SLIP.pdf},
	Number = {7},
	Pages = {370--372},
	Publisher = {ACM Press},
	Title = {Recovery of reentrant list structures in {SLIP}},
	Volume = {12},
	Year = {1969}}

@inproceedings{Reeuw02,
	Address = {New York, NY, USA},
	Annote = {Java classes are very flexible, but this comes at a price. The main cost is that every class instance must be dynamically allocated. Their access by reference introduces pointer dereferences and complicates program analysis. These costs are particularly burdensome for small, ubiquitous data structures such as coordinates and state vectors. For such data structures a lightweight representation is desirable, allowing such data to be handled directly, similar to primitive types. A number of proposals introduce restricted or mutated variants of standard Java classes that could serve as lightweight representation, but the impact of these proposals has never been studied.Since we have implemented a Java compiler with lightweight data structures we are in a good position to do this evaluation. Our lightweight data structures are tuples. As we will show, their use can result in significant performance gains: for a number of existing benchmark programs using tuples we gain more than 50% in performance relative to our own compiler, and more than 20% relative to Sun's Hotspot 1.4 compiler. We expect similar performance gains for other implementations of lightweight data structures.With respect to the expressiveness of Java, lightweight variants of standard Java classes have little impact. In contrast, tuples add a different language construct that, as we will show, can lead to substantially more concise program code.},
	Author = {C. van Reeuwijk and H. J. Sips},
	Booktitle = {JGI '02: Proceedings of the 2002 joint ACM-ISCOPE conference on Java Grande},
	Date-Modified = {2005-04-21 12:40:05 +0300},
	Doi = {http://doi.acm.org/10.1145/583810.583831},
	Isbn = {1-58113-599-8},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Adding%20tuples%20to%20Java-%20a%20study%20in%20lightweight%20data%20structures.pdf},
	Location = {Seattle, Washington, USA},
	Pages = {185--191},
	Publisher = {ACM Press},
	Title = {Adding tuples to Java: a study in lightweight data structures},
	Year = {2002}}

@inproceedings{Wilso95,
	Author = {Wilson, Paul R. and Johnstone, Mark S. and Neely, Michael and Boles, David},
	Booktitle = {Proceedings of the International Workshop on Memory Management},
	Date-Modified = {2005-05-05 11:54:05 +0300},
	Editor = {Henry G. Baker},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Dynamic%20Storage%20Allocation-%20A%20Survey%20and%20Critical%20Review.pdf},
	Location = {Kinross Scotland (UK)},
	Month = sep,
	Note = {Lecture Notes in Computer Science 986},
	Pages = {1--116},
	Publisher = {Springer-Verlag},
	Title = {{D}ynamic {S}torage {A}llocation: {A S}urvey and {C}ritical {R}eview},
	Url = {http://csapp.cs.cmu.edu/public/docs/dsa.ps},
	Year = {1995}}

@inproceedings{Bacon01,
	Abstract = {ObJect-oriented programming languages have always distinguished  between "primitive" and "user-defined" data types, and in the case  of languages like C++ and Java, the primitives are not even treated  as objects, further fragmenting the programming model.  The dis-  tinction is especially problematic when a particular programrning  community requires primitive-level support for a new data type, as  for complex, intervals, fixed-pointed numbers, and so on.  We present Kava, a design for a backward-compatible version  of Java that solves the problem of programmable lightweight ob-  jects in a much more aggressive and uniform manner than previous  proposals.  In Kava, there are no primitive types; instead, object-  oriented programming is provided down to the level of single bits,  and types such as int can be explicitly programmed within the lan-  guage.  While the language maintains a uniform object reference  semantics, efficiency is obtained by making heavy use of unboxing  and semantic expansion.  We describe Kava as a dialect of the Java language, show how  it can be used to define various primitive types, describe how it  can be translated into Java, and compare it to other approaches to  lightweight objects.},
	Address = {New York, NY, USA},
	Author = {David F. Bacon},
	Booktitle = {JGI '01: Proceedings of the 2001 joint ACM-ISCOPE conference on Java Grande},
	Date-Modified = {2005-05-05 11:59:56 +0300},
	Doi = {http://doi.acm.org/10.1145/376656.376812},
	Isbn = {1-58113-359-6},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Kava-%20A%20Java%20Dialect%20with%20a%20Uniform%20Object%20Model%20%20for%20Lightweight%20Classes.pdf},
	Location = {Palo Alto, California, United States},
	Pages = {68--77},
	Publisher = {ACM Press},
	Title = {Kava: a {J}ava dialect with a uniform object model for lightweight classes},
	Year = {2001}}

@article{Colli60,
	Abstract = {An important property of the Newell Shaw-Simon scheme for computer storage of lists is that data having multiple occurrences need not be stored at more than one place in the computer. That is, lists may be ``overlapped.'' Unfortunately, overlapping poses a problem for subsequent erasure. Given a list that is no longer needed, it is desired to erase just those parts that do not overlap other lists. In LISP, McCarthy employs an elegant but inefficient solution to the problem. The present paper describes a general method which enables efficient erasure. The method employs interspersed reference counts to describe the extent of the overlapping.},
	Address = {New York, NY, USA},
	Author = {George E. Collins},
	Date-Modified = {2005-06-22 15:54:47 +0300},
	Doi = {http://doi.acm.org/10.1145/367487.367501},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20method%20for%20overlapping%20and%20erasure%20of%20lists.pdf},
	Number = {12},
	Pages = {655--657},
	Publisher = {ACM Press},
	Title = {A Method for Overlapping and Erasure of Lists},
	Volume = {3},
	Year = {1960}}

@inproceedings{Appel88,
	Address = {New York, NY, USA},
	Annote = {The read barrier inefficiency of Baker's algorithm has led many researchers to investigate ways of reducing its cost. An interesting approach is presented in [Appel et al., 1988]. The authors employ the operating system's virtual memory subsystem to implement the read barrier. The pages in to-space are all initially locked. When the mutator tries to access a field, the page access trap generated by the operating system is caught by the collector, which in turn copies all referenced objects from from-space in new to-space pages that are locked by default. A variation of the algorithm for parallel collection uses a background thread that scans locked pages between collections. Unfortunately, in order to avoid large amounts of page faults from accessing locked pages, the background thread must be run in kernel mode. The Appel-Ellis-Li collector does not support objects larger than a page. Also, being based on virtual memory, it cannot classify as a real-time collector. },
	Author = {A. W. Appel and J. R. Ellis and K. Li},
	Booktitle = {PLDI '88: Proceedings of the ACM SIGPLAN 1988 conference on Programming Language design and Implementation},
	Date-Modified = {2005-04-06 12:47:02 +0300},
	Doi = {http://doi.acm.org/10.1145/53990.53992},
	Isbn = {0-89791-269-1},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Real-time%20concurrent%20collection%20on%20stock%20multiprocessors.pdf},
	Location = {Atlanta, Georgia, United States},
	Pages = {11--20},
	Publisher = {ACM Press},
	Title = {Real-time concurrent collection on stock multiprocessors},
	Year = {1988}}

@article{Deuts76,
	Abstract = {This paper describes a new way of solving the storage reclamation problem for a system such as Lisp that allocates storage automatically from a heap, and does not require the programmer to give any indication that particular items are no longer useful or accessible. A reference count scheme for reclaiming non-self-referential structures, and a linearizing, compacting, copying scheme to reorganize all storage at the users discretion are proposed. The algorithms are designed to work well in systems which use multiple levels of storage, and large virtual address space. They depend on the fact that most cells are referenced exactly once, and that reference counts need only be accurate when storage is about to be reclaimed. A transaction file stores changes to reference counts, and a multiple reference table stores the count for items which are referenced more than once.},
	Address = {New York, NY, USA},
	Annote = {An optimisation for reference counting schemes that addresses both the problem of circular object structures and pointer update costs is deferred reference counting~\cite{Deuts76}. The algorithm is based on the observation that most pointer stores are made on local variables and therefore most objects' reference counts are one~\cite{Zorn89}. A table, aptly named Zero Count Table ({\sc zct}), holds references to objects whose reference count is zero. Those references are created (or destroyed) during updates to pointer variables. Periodically, or when full, the {\sc zct} table is reconciled and objects whose entries exist in the table, are returned to the free list. In the initial design, the algorithm used disk files to store pointer update information in the form of transactions to minimise memory consumption. It also proposed two more tables, the Multiple Reference Table and the Variable Reference Table, in order to speed up searches in the transaction files, when the transactions where not 'committed' to the main memory. Today's computers do not require the overhead of transaction files. The deferred reference counting algorithm is very efficient in minimising the cost of pointer updates. Studies by~\cite{Ungar84}
have shown that deferred reference counting can cut the costs of pointer updates by more than 500\% while reducing the total amount of time spent in {\sc gc} by almost 50\%. },
	Author = {L. Peter Deutsch and Daniel G. Bobrow},
	Date-Modified = {2005-05-20 10:37:51 +0300},
	Doi = {http://doi.acm.org/10.1145/360336.360345},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/An%20efficient,%20incremental,%20automatic%20garbage%20collector.pdf},
	Number = {9},
	Pages = {522--526},
	Publisher = {ACM Press},
	Title = {An efficient, incremental, automatic garbage collector},
	Volume = {19},
	Year = {1976}}

@inproceedings{Wilso92,
	Address = {London, UK},
	Author = {Paul R. Wilson},
	Booktitle = {IWMM '92: Proceedings of the International Workshop on Memory Management},
	Date-Modified = {2005-04-01 16:38:38 +0300},
	Isbn = {3-540-55940-X},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Uniprocessor%20Garbage%20Collection%20Techniques.pdf},
	Pages = {1--42},
	Publisher = {Springer-Verlag},
	Title = {Uniprocessor Garbage Collection Techniques},
	Year = {1992}}

@inproceedings{Saun64,
	Author = {Robert A. Saunders},
	Comments = {Uses Edwards' two pointer compactifying algorithm},
	Crossref = {berk64},
	Date-Modified = {2005-04-01 16:39:16 +0300},
	Pages = {220--231},
	Title = {The {LISP} System for the {Q--32} Computer},
	Year = {1964}}

@inproceedings{Dolig93,
	Abstract = {This paper presents the design and implementation of a ``quasi real-time'' garbage collector for Concurrent Caml Light, an implementation of ML with threads. This two-generation system combines a fast, asynchronous copying collector on the young generation with a non-disruptive concurrent marking collector on the old generation. This design crucially relies on the ML compile-time distinction between mutable and immutable objects.},
	Address = {New York, NY, USA},
	Author = {Damien Doligez and Xavier Leroy},
	Booktitle = {POPL '93: Proceedings of the 20th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	Date-Modified = {2005-03-30 12:26:16 +0300},
	Doi = {http://doi.acm.org/10.1145/158511.158611},
	Isbn = {0-89791-560-7},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20concurrent,%20generational%20garbage%20collector%20for%20a%20multithreaded%20implementation%20of%20ML.pdf},
	Location = {Charleston, South Carolina, United States},
	Pages = {113--123},
	Publisher = {ACM Press},
	Title = {A concurrent, generational garbage collector for a multithreaded implementation of ML},
	Year = {1993}}

@inproceedings{Hoski92,
	Abstract = {Generational  garbage  collectors  are able to achieve  very  small  pause  times  by  concentrating  on  the  youngest  (most  recently  allocated)  objects  when  collecting,  since  objects  have  been  observed  to die  young  in many  sys-  tems.  Generational  collectors  must  keep  track  of  all  pointers  from  older  to younger  generations,  by  ``monitoring''  all stores  into  the  heap.  This  write barrier  has  been  implemented  in a number  of ways,  varying  essen-  tially  in the granularity  of the information  observed  and  stored.  Here  we  examine  a range  of  write  barrier  im-  plementations  and  evaluate  their  relative  performance  within  a  generation  scavenging  garbage  collector  for  Smalltalk. },
	Address = {New York, NY, USA},
	Author = {Antony L. Hosking and J. Eliot B. Moss and Darko Stefanovic},
	Booktitle = {OOPSLA '92: conference proceedings on Object-oriented programming systems, languages, and applications},
	Date-Modified = {2005-03-30 12:19:11 +0300},
	Doi = {http://doi.acm.org/10.1145/141936.141946},
	Isbn = {0-201-53372-3},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20comparative%20performance%20evaluation%20of%20write%20barrier%20implementation.pdf},
	Location = {Vancouver, British Columbia, Canada},
	Pages = {92--109},
	Publisher = {ACM Press},
	Title = {A comparative performance evaluation of write barrier implementation},
	Year = {1992}}

@inproceedings{Boehm93,
	Abstract = {We call a garbage collector conservative if it has only partial information about the location of pointers, and is thus forced to treat arbitrary bit patterns as though they might be pointers, in at least some cases. We show that some very inexpensive, but previously unused techniques can have dramatic impact on the effectiveness of conservative garbage collectors in reclaiming memory. Our most significant observation is that static data that appears to point to the heap should not result in misidentified references to the heap. The garbage collector has enough information to allocate around such references. We also observe that programming style has a significant impact on the amount of spuriously retained storage, typically even if the collector is not terribly conservative. Some fairly common C and C++ programming style significantly decrease the effectiveness of any garbage collector. These observations suffice to explain some of the different assessments of conservative collection that have appeared in the literature.},
	Address = {New York, NY, USA},
	Author = {Hans-Juergen Boehm},
	Booktitle = {PLDI '93: Proceedings of the ACM SIGPLAN 1993 conference on Programming language design and implementation},
	Date-Modified = {2005-03-30 12:22:04 +0300},
	Doi = {http://doi.acm.org/10.1145/155090.155109},
	Isbn = {0-89791-598-4},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Space%20efficient%20conservative%20garbage%20collection.pdf},
	Location = {Albuquerque, New Mexico, United States},
	Pages = {197--206},
	Publisher = {ACM Press},
	Title = {Space efficient conservative garbage collection},
	Year = {1993}}

@article{Guy-L75,
	Abstract = {Algorithms for a multiprocessing compactifying garbage collector are presented and discussed. The simple case of two processors, one performing LISP-like list operations and the other performing garbage collection continuously, is thoroughly examined. The necessary capabilities of each processor are defined, as well as interprocessor communication and interlocks. Complete procedures for garbage collection and for standard list processing primitives are presented and thoroughly explained. Particular attention is given to the problems of marking and relocating list cells while another processor may be operating on them. The primary aim throughout is to allow the list processor to run unimpeded while the other processor reclaims list storage The more complex case involving several list processors and one or more garbage collection processors are also briefly discussed.},
	Annote = {Guy Steele proposed a similar mark-sweep approach that uses 2 processors which can be used interchangeably (but not concurrently) as garbage collectors. The algorithm uses two bits per object to specify the object state, one of them used as semaphore and one as the mark indicator and a stack per processor to temporarily store object nodes while traversing the object graph. The GC cycle consists of four phases during which the collector marks reachable objects, relocates marked objects in order to compact the heap, updates pointers of existing objects to the new location of the relocated objects and finally reclaims free cells to the free memory list. The mutator can freely allocate new memory while the collector is working; synchronisation is achieved using a system-wide semaphore that locks the collector and forces the mutator to wait until a safe point is reached by the collector. },
	Author = {Guy L. Steele, Jr.},
	Date-Modified = {2005-04-01 13:19:38 +0300},
	Doi = {http://doi.acm.org/10.1145/361002.361005},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Multiprocessing%20compactifying%20garbage%20collection.pdf},
	Number = {9},
	Pages = {495--508},
	Publisher = {ACM Press},
	Title = {Multiprocessing compactifying garbage collection},
	Volume = {18},
	Year = {1975}}

@book{berk64,
	Address = {Cambridge, MA},
	Booktitle = {The Programming Language {LISP}: Its Operation and Applications},
	Edition = {Fourth},
	Editor = {E. C. Berkeley and Daniel G. Bobrow},
	Publisher = {Information International, Inc.},
	Title = {The Programming Language {LISP}: Its Operation and Applications},
	Year = {1974}}

@inproceedings{OTool94,
	Abstract = {We have implemented a concurrent copying garbage collector that uses replicating garbage collection. In our design, the client can continuously access the heap during garbage collection. No low-level synchronization between the client and the garbage collector is required on individual object operations. The garbage collector replicates live heap objects and periodically synchronizes with the client to obtain the client's current root set and mutation log. An experimental implementation using the Standard ML of New Jersey system on a shared-memory multiprocessor demonstrates excellent pause time performance and moderate execution time speedups.},
	Author = {James O'Toole and Scott Nettles},
	Booktitle = {LFP '94: Proceedings of the 1994 ACM conference on LISP and functional programming},
	Date-Modified = {2005-03-23 16:28:12 +0200},
	Doi = {http://doi.acm.org/10.1145/182409.182425},
	Isbn = {0-89791-643-3},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Concurrent%20replicating%20garbage%20collection.pdf},
	Location = {Orlando, Florida, United States},
	Pages = {34--42},
	Publisher = {ACM Press},
	Title = {Concurrent replicating garbage collection},
	Year = {1994}}

@article{Wadle76,
	Abstract = { A real time garbage collection system avoids suspending the operations of a list processor for the long times that garbage collection normally requires by performing garbage collection on a second processor in parallel with list processing operations, or on a single processor time-shared with them. Algorithms for recovering discarded list structures in this manner are presented and analyzed to determine sufficient conditions under which the list processor never needs to wait on the collector. These techniques are shown to require at most twice as much processing power as regular garbage collectors, if they are used efficiently. The average behavior of the program is shown to be very nearly equal to the worst-case performance, so that the sufficient conditions are also suitable for measuring the typical behavior of the algorithm.
},
	Author = {Philip L. Wadler},
	Date-Modified = {2005-04-01 13:19:50 +0300},
	Doi = {http://doi.acm.org/10.1145/360336.360338},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Analysis%20of%20an%20algorithm%20for%20real%20time%20garbage%20collection.pdf},
	Number = {9},
	Pages = {491--500},
	Publisher = {ACM Press},
	Title = {Analysis of an algorithm for real time garbage collection},
	Volume = {19},
	Year = {1976}}

@article{Chene70,
	Abstract = {A simple nonrecursive list structure compacting scheme or garbage collector suitable for both compact and LISP-like list structures is presented. The algorithm avoids the need for recursion by using the partial structure as it is built up to keep track of those lists that have been copied.},
	Annote = {Cheney  described one of the first copying collectors (then called list compactors). His algorithm uses a two pass scan, that first copies all items (memory cells with data and a next pointer) to consecutive addresses and then updates pointers of non-items (memory cells only containing pointers) to the correct addresses.},
	Author = {C. J. Cheney},
	Date-Modified = {2005-03-28 12:35:16 +0300},
	Doi = {http://doi.acm.org/10.1145/362790.362798},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20nonrecursive%20list%20compacting%20algorithm.pdf},
	Number = {11},
	Pages = {677--678},
	Publisher = {ACM Press},
	Title = {A nonrecursive list compacting algorithm},
	Volume = {13},
	Year = {1970}}

@inproceedings{Nettl93,
	Abstract = { We have implemented the first copying garbage collector that permits continuous unimpeded mutator access to the original objects during copying. The garbage collector incrementally replicates all accessible objects and uses a mutation log to bring the replicas up-to-date with changes made by the mutator. An experimental implementation demonstrates that the costs of using our algorithm are small and that bounded pause times of 50 milliseconds can be readily achieved.
},
	Author = {Scott Nettles and James O'Toole},
	Booktitle = {PLDI '93: Proceedings of the ACM SIGPLAN 1993 conference on Programming language design and implementation},
	Date-Modified = {2005-03-23 16:11:27 +0200},
	Doi = {http://doi.acm.org/10.1145/155090.155111},
	Isbn = {0-89791-598-4},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Real-time%20replication%20garbage%20collection.pdf},
	Location = {Albuquerque, New Mexico, United States},
	Pages = {217--226},
	Publisher = {ACM Press},
	Title = {Real-time replication garbage collection},
	Year = {1993}}

@article{Morri78,
	Abstract = {Given an area of storage containing scattered, marked nodes of differing sizes, one may wish to rearrange them into a compact mass at one end of the area while revising all pointers to marked nodes to show their new locations. An algorithm is described here which accomplishes this task in linear time relative to the size of the storage area, and in a space of the order of one bit for each pointer. The algorithm operates by reversibly encoding the situation (that a collection of locations point to a single location) by a linear list, emanating from the pointed-to location, passing through the pointing locations, and terminating with the pointed-to location's transplanted contents.},
	Author = {F. Lockwood Morris},
	Date-Modified = {2005-03-04 14:30:28 +0200},
	Doi = {http://doi.acm.org/10.1145/359576.359583},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20time-%20and%20space-efficient%20garbage%20compaction%20algorithm.pdf},
	Number = {8},
	Pages = {662--665},
	Publisher = {ACM Press},
	Title = {A time- and space-efficient garbage compaction algorithm},
	Volume = {21},
	Year = {1978}}

@inproceedings{Endo97,
	Abstract = {This work describes implementation of a mark-sweep garbage collector (GC) for shared-memory machines and reports its performance. It is a simple ''parallel'' collector in which all processors cooperatively traverse objects in the global shared heap. The collector stops the application program during a collection and assumes a uniform access cost to all locations in the shared heap. Implementation is based on the Boehm-Demers-Weiser conservative GC (Boehm GC). Experiments have been done on Ultra Enterprise 10000 (Ultra Sparc processor 250 MHz, 64 processors). We wrote two applications, BH (an N-body problem solver) and CKY (a context free grammar parser) in a parallel extension to C++.Through the experiments, We observe that load balancing is the key to achieving scalability. A naive collector without load redistribution hardly exhibits speed-up (at most fourfold speed-up on 64 processors). Performance can be improved by dynamic load balancing, which exchanges objects to be scanned between processors, but we still observe that straightforward implementation severely limits performance. First, large objects become a source of significant load imbalance, because the unit of load redistribution is a single object. Performance is improved by splitting a large object into small pieces before pushing it onto the mark stack. Next, processors spend a significant amount of time uselessly because of serializing method for termination detection using a shared counter. This problem suddenly appeared on more than 32 processors. By implementing non-serializing method for termination detection, the idle time is eliminated and performance is improved. With all these careful implementation, we achieved average speed-up of 28.0 in BH and 28.6 in CKY on 64 processors.},
	Annote = {presents one of the first attempts to implement a scalable garbage collector by distributing load among processors. The conservative mark-sweep implementation for the {\sc c++} language first introduced in \todo{ref for space efficient conservative garbage collection} was used as a basis. During the marking phase, the collector uses a stack per processor to hold local roots and objects to be traversed and a queue into which the processor periodically uploads parts of its local stack. When a processor's local stack becomes empty, it queries adjacent processors' shared queues for objects to be marked. For the sweep phase, each processor uses its own reclamation list; at the end of the sweep phase, local reclamation lists are joined, adjacent addresses are coalesced and the allocator's free list is updated. Performance figures provided by the authors show an average speedup of 28 times on 64 processors.},
	Author = {Toshio Endo and Kenjiro Taura and Akinori Yonezawa},
	Booktitle = {Supercomputing '97: Proceedings of the 1997 ACM/IEEE conference on Supercomputing (CDROM)},
	Date-Modified = {2005-03-29 13:56:31 +0300},
	Doi = {http://doi.acm.org/10.1145/509593.509641},
	Isbn = {0-89791-985-8},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20scalable%20mark-sweep%20garbage%20collector%20on%20large-scale%20shared-memory%20machines.pdf},
	Location = {San Jose, CA},
	Pages = {1--14},
	Publisher = {ACM Press},
	Title = {A scalable mark-sweep garbage collector on large-scale shared-memory machines},
	Year = {1997}}

@inproceedings{Dolig94,
	Abstract = {We describe and prove the correctness of a new concurrent mark-and-sweep garbage collection algorithm. This algorithm derives from the classical on-the-fly algorithm from Dijkstra et al. [9]. A distinguishing feature of our algorithm is that it supports multiprocessor environments where the registers of running processes are not readily accessible, without imposing any overhead on the elementary operations of loading a register or reading or initializing a field. Furthermore our collector never blocks running mutator processes except possibly on requests for free memory; in particular, updating a field or creating or marking or sweeping a heap object does not involve system-dependent synchronization primitives such as locks. We also provide support for process creation and deletion, and for managing an extensible heap of variable-sized objects.},
	Annote = {The authors state the assumption that barriers between the mutator and the heap place a significant overhead on most mutator operations. They describe a GC algorithm that allocates objects in two different regions of the heap. Mutable objects are shared by all mutator threads and are placed on the main heap while immutable objects are allocated on a thread-local heap. Within a thread-local heap, a copying GC is used; surviving objects are promoted to the global heap. The global heap is managed by a concurrent mark-sweep variant of Dijktra's on-the-fly algorithm. Synchronisation is avoided in thread-local minor GC cycles because no external references exist to objects in the local heap. When a write operation is required, the object and its decedents are copied to the global heap, while a forwarding pointer is left to the local heap for the next minor GC cycle, but even then synchronisation is only required for allocating the required space. The mutator threads are required to co-operate with the collector in order to propagate updates of root objects (pointers in registers and on the stack); this is achieved through a complex protocol that involves reading of a global state variable set by the garbage collector and synchronising to it. This type of synchronisation is far less often than write barrier synchronisation, as stated by the authors. The performance of a slightly earlier version of the algorithm is measured in and indeed major collection load was less than 5% while minor collections finished in less than 10 ms under full load on a 14 processor machine.},
	Author = {Damien Doligez and Georges Gonthier},
	Booktitle = {POPL '94: Proceedings of the 21st ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	Date-Modified = {2005-03-29 18:30:42 +0300},
	Doi = {http://doi.acm.org/10.1145/174675.174673},
	Isbn = {0-89791-636-0},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Portable,%20unobtrusive%20garbage%20collection%20for%20multiprocessor%20systems.pdf},
	Location = {Portland, Oregon, United States},
	Pages = {70--83},
	Publisher = {ACM Press},
	Title = {Portable, unobtrusive garbage collection for multiprocessor systems},
	Year = {1994}}

@inproceedings{Blell99,
	Abstract = {This paper presents the first multiprocessor garbage collection algorithm with provable bounds on time and space. The algorithm is a real-time shared-memory copying collector. We prove that the algorithm requires at most 2(R(l + 2/k) + N + 5PD) memory locations, where P is the number of processors, R is the maximum reachable space during a computation (number of locations accessible from the root set), N is the maximum number of reachable objects, D is the maximum depth of any data object, and k is a parameter specifying how many locations are copied each time a location is allocated. Furthermore we show that client threads are never stopped for more than time proportional to k non-blocking machine instructions. The bounds are guaranteed even with arbitrary length arrays. The collector only requires write-barriers (reads are unaffected by the collector), makes few assumptions about the threads that are generating the garbage, and allows them to run mostly asynchronously.},
	Annote = {A copying parallel GC that also features real-time behaviour and load distribution is presented. Blelloch uses a variation of the tri\-color abstraction to model the heap; objects are white when the collector starts and become grey them when space is reserved for them in the to\-space. A replica of the object graph in the from\-space is eventually created in the to\-space by the collector. The mutator has read-only access on objects in the from-space and should a write occurs, a write barrier forces synchronisation of both graphs. Pointers in the object's header point from the from-space to the to-space copy. The collector copies incrementally the object's fields to the to-space; when the copy is complete the object is painted black. In order to distribute load among processors, they keep track of all grey objects to per-processor stacks and also have global stack where processors periodically upload parts of their stacks for idle processors to use.},
	Author = {Guy E. Blelloch and Perry Cheng},
	Booktitle = {PLDI '99: Proceedings of the ACM SIGPLAN 1999 conference on Programming language design and implementation},
	Date-Modified = {2005-03-22 12:07:01 +0200},
	Doi = {http://doi.acm.org/10.1145/301618.301648},
	Isbn = {1-58113-094-5},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/On%20bounding%20time%20and%20space%20for%20multiprocessor%20garbage%20collection.pdf},
	Location = {Atlanta, Georgia, United States},
	Pages = {104--117},
	Publisher = {ACM Press},
	Title = {On bounding time and space for multiprocessor garbage collection},
	Year = {1999}}

@article{Baker78,
	Abstract = { A real-time list processing system is one in which the time required by the elementary list operations (e.g. CONS, CAR, CDR, RPLACA, RPLACD, EQ, and ATOM in LISP) is bounded by a (small) constant. Classical implementations of list processing systems lack this property because allocating a list cell from the heap may cause a garbage collection, which process requires time proportional to the heap size to finish. A real-time list processing system is presented which continuously reclaims garbage, including directed cycles, while linearizing and compacting the accessible cells into contiguous locations to avoid fragmenting the free storage pool. The program is small and requires no time-sharing interrupts, making it suitable for microcode. Finally, the system requires the same average time, and not more than twice the space, of a classical implementation, and those space requirements can be reduced to approximately classical proportions by compact list representation. Arrays of different sizes, a program stack, and hash linking are simple extensions to our system, and reference counting is found to be inferior for many applications.
},
	Annote = {Baker, in his classic paper on real-time list processing, was one of the first to derive bounds on time and space for uniprocessor garbage collection. Baker's algorithm uses Cheney's copying list compactor as a basis; the main difference is that Baker's algorithm is incremental by requiring a constant $kn$ words to be traced after an allocation of $n$ words. The algorithm also uses a read barrier that copies objects to to-space when they are first accessed. Allocations are also performed in to-space. By trapping all access from to-space to from-space and allocating in the to-space, the mutator is effectively isolated in the to-space. Baker's algorithm cannot be considered as real-time by the strict definition of the term presented above; the read barrier is far too expensive to allow small amounts of latency and moreover the cost of accessing an object depends on how deep in the object hierarchy this object is and to whether the path to the object has already been copied to the to-space. However, it was the first algorithm to present a bounded number of steps for many of its operations (e.g. allocation) while requiring a constant amount of space ($2R(1+1/k)$ where $R$ is the reachable space).},
	Author = {Henry G. Baker},
	Date-Modified = {2005-04-05 14:54:36 +0300},
	Doi = {http://doi.acm.org/10.1145/359460.359470},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/List%20processing%20in%20real%20time%20on%20a%20serial%20computer.pdf},
	Number = {4},
	Pages = {280--294},
	Publisher = {ACM Press},
	Title = {List processing in real time on a serial computer},
	Volume = {21},
	Year = {1978}}

@article{Dijks78,
	Abstract = {As an example of cooperation between sequential processes with very little mutual interference despite frequent manipulations of a large shared data space, a technique is developed which allows nearly all of the activity needed for garbage detection and collection to be performed by an additional processor operating concurrently with the processor devoted to the computation proper. Exclusion and synchronization constraints have been kept as weak as could be achieved; the severe complexities engendered by doing so are illustrated.},
	Annote = {Dijktra proposes a mark-sweep garbage collector utilising two processors; one is the mutator (executes the program) and another one dedicated to garbage collection. In order to prove his solution, he also invented the graph colouring abstraction. 

The graph colouring abstraction models the memory cells as a set of interconnected graph nodes. All nodes are initially white. The marking phase consists of painting reachable objects black. Since the mutator operation can be interleaved with the collector, the white nodes attached to black nodes while the marking phase is not complete are painted grey. When the collector visits a grey node its paints it black and also paints grey all its white successors (black or grey nodes are left unchanged). The marking phase concludes when no nodes are left grey. Obviously, all  nodes left white are garbage. The collection phase consists of appending white nodes to the free memory list and painting white black nodes. By specifying certain operations as atomic, such as shading a node and its successors, it can be proven that this algorithms does not suffer from concurrency problems. },
	Author = {Edsger W. Dijkstra and Leslie Lamport and A. J. Martin and C. S. Scholten and E. F. M. Steffens},
	Date-Modified = {2005-03-20 20:02:37 +0200},
	Doi = {http://doi.acm.org/10.1145/359642.359655},
	Issn = {0001-0782},
	Journal = {Commun. ACM},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/On-the-fly%20garbage%20collection%20An%20exercise%20in%20cooperation.pdf},
	Number = {11},
	Pages = {966--975},
	Publisher = {ACM Press},
	Title = {On-the-fly garbage collection: an exercise in cooperation},
	Volume = {21},
	Year = {1978}}

@article{Cohen81,
	Abstract = {A concise and unified view of the numerous existing algorithms for performing garbage
collection of linked data structures is presented. The emphasis is on garbage collection
proper, rather than on storage allocatlon. First, the classical garbage collection algorithms are reviewed, and their marking and collecting phases, with and without compacting, are discussed. Algorithms describing these phases are classified according to the type of cells to be collected: those for collecting single-sized cells are simpler than those for varisized cells. Recently proposed algorithms are presented and compared with the classical ones.
Special topics in garbage collection are also covered: the use of secondary and virtual
storage, the use of reference counters, parallel and real-time collections, analyses of
garbage collection algorithms, and language features whlch influence the design of
collectors. The bibhography, wlth topical annotations, contains over 100 references.
},
	Annote = { },
	Author = {Jacques Cohen},
	Date-Modified = {2005-03-07 15:58:31 +0200},
	Doi = {http://doi.acm.org/10.1145/356850.356854},
	Issn = {0360-0300},
	Journal = {ACM Comput. Surv.},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Garbage%20Collection%20of%20Linked%20Data%20Structures.pdf},
	Number = {3},
	Pages = {341--367},
	Publisher = {ACM Press},
	Title = {Garbage Collection of Linked Data Structures},
	Volume = {13},
	Year = {1981}}

@article{Skoti02,
	Abstract = {Dynamic memory management has been an important part of a large class of computer programs and with the recent popularity of object oriented programming languages, more specifically Java, high performance dynamic memory management algorithms continue to be of great importance. In this paper, an analysis of Java programs, provided by the SPECjvm98 benchmark suite, and their behavior, as this relates to fragmentation, is performed. Based on this analysis, a new model is proposed which allows the estimation of the total internal fragmentation that Java systems will incur prior to the programs execution. The proposed model can also accommodate any variation of segregated lists implementation. A comparison with a previously introduced fragmentation model is performed as well as a comparison with actual fragmentation values that were extracted from SPECjvm98. Finally the idea of a test-bed application that will use the proposed model to provide to programmers/developers the ability to know, prior to a programs execution, the fragmentation and memory utilization of their programs, is also introduced. With this application at hand developers as well as designers of applications could better assess the stability, efficiency as well reliability of their applications at compile time.},
	Author = {Therapon Skotiniotis and Ji-en Morris Chang},
	Date-Modified = {2005-05-05 11:58:45 +0300},
	Journal = {Journal of Systems and Software},
	Month = {December},
	Number = {3},
	Pages = {235--246},
	Title = {Estimating internal memory fragmentation for {J}ava programs},
	Volume = {64},
	Year = {2002}}

@article{Cohen83,
	Abstract = {The relative efficiencies of four compactors of varisized cells are estimated by constructing their time-  formulas. These are symbolic formulas expressing execution times as functions of the time to perform  common, elementary operations such as assignment, addition, subscripting, and loop overhead.  By  binding the variables to numeric values corresponding to a specific machine one can estimate program  execution times without resorting to empirical tests. The first of the compactors  (Lisp 2) requires  additional storage for pointer readjustment. The second (based on the work of Haddon and Waite)  attempts to reduce these storage requirements at the expense of processing time. The last two (Morris'  and Jonkers') are recently proposed  compactors  that require minimal additional storage  and that  update pointers by first threading them into linear lists. The paper provides unified descriptions  of  the algorithms and presents curves expressing the relative efficiencies of the compactors when run on  a specific machine (PDP-10). It is straightforward  to modify the given formulas to estimate compac-  tors' efficiencies when run on other computers.  },
	Author = {Jacques Cohen and Alexandru Nicolau},
	Date-Modified = {2005-03-04 14:14:54 +0200},
	Doi = {http://doi.acm.org/10.1145/69575.357226},
	Issn = {0164-0925},
	Journal = {ACM Trans. Program. Lang. Syst.},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Comparison%20of%20Compacting%20Algorithms%20for%20Garbage%20Collection.pdf},
	Number = {4},
	Pages = {532--553},
	Publisher = {ACM Press},
	Title = {Comparison of Compacting Algorithms for Garbage Collection},
	Volume = {5},
	Year = {1983}}

@article{Ben-A84,
	Abstract = {A  new algorithm is described for on-the-fly garbage collection. The new algorithm uses only two  colors and has a  simple correctness proof. Two variations on the algorithm are then derived: One  attempts to minimize the amount of marking that must be done, and the other is an incremental  garbage collector.  },
	Author = {Mordechai Ben-Ari},
	Date-Modified = {2005-03-03 13:24:58 +0200},
	Doi = {http://doi.acm.org/10.1145/579.587},
	Issn = {0164-0925},
	Journal = {ACM Trans. Program. Lang. Syst.},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Algorithms%20for%20on-the-fly%20garbage%20collection.pdf},
	Number = {3},
	Pages = {333--344},
	Publisher = {ACM Press},
	Title = {Algorithms for on-the-fly garbage collection},
	Volume = {6},
	Year = {1984}}

@article{Inoue88,
	Abstract = {We propose a method for detecting the generation of garbage cells by analyzing a source text written in a functional programming language which uses ordinary linked lists to implement list-type values. For a subexpression such as F(G( . . . )) in a program where the function values of F and G are of list type, if a cell c is created during the computation of G and if c does not appear in a list-type value of F, then c becomes a garbage cell at the end of the computation of F. We discuss this problem on the basis of formal languages derived from the functional program text and show some sufficient conditions that predict the generation of garbage cells. Also, we give an efficient algorithm to detect at compile time the generation of garbage cells which are linearly linked. We have implemented these algorithms in an experimental LISP system. By executing several sample programs on the system, we conclude that our method is effective in detecting the generation of garbage cells.},
	Author = {Katsuro Inoue and Hiroyuki Seki and Hikaru Yagi},
	Date-Modified = {2005-03-03 14:33:48 +0200},
	Doi = {http://doi.acm.org/10.1145/48022.48025},
	Issn = {0164-0925},
	Journal = {ACM Trans. Program. Lang. Syst.},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Analysis%20of%20functional%20programs%20to%20detect%20run-time%20garbage%20cells.pdf},
	Number = {4},
	Pages = {555--578},
	Publisher = {ACM Press},
	Title = {Analysis of functional programs to detect run-time garbage cells},
	Volume = {10},
	Year = {1988}}

@article{Wise79,
	Abstract = {The two-pass compaction algorithm of F.L. Morris, which follows upon the mark phase in a garbage collector, may be modified to recover reference counts for a hybrid storage management system. By counting the executions of two loops in that algorithm where upward and downward references, respectively, are forwarded to the relocation address of one node, we can initialize a count of active references and then update it but once. The reference count may share space with the mark bit in each node, but it may not share the additional space required in each pointer by Morris's algorithm, space which remains unused outside the garbage collector.},
	Author = {David S. Wise},
	Date-Modified = {2005-03-02 15:30:52 +0200},
	Doi = {http://doi.acm.org/10.1145/357062.357070},
	Issn = {0164-0925},
	Journal = {ACM Trans. Program. Lang. Syst.},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Morris's%20Garbage%20Compaction%20Algorithm%20Restores%20Reference%20Counts.pdf},
	Number = {1},
	Pages = {115--120},
	Publisher = {ACM Press},
	Title = {Morris's Garbage Compaction Algorithm Restores Reference Counts},
	Volume = {1},
	Year = {1979}}

@article{Bobro80,
	Abstract = { Automatic storage management requires that one identify storage unreachable by a user's program and return it to free status. One technique maintains a count of the references from user's programs to each cell, since a count of zero implies the storage is unreachable. Reentrant structures are self-referencing; hence no cell in them will have a count of zero, even though the entire structure is unreachable. A modification of standard reference counting can be used to manaage the deallocation of a large class of frequently used reentrant structures, including two-way and circularly linked lists. All the cells of a potentially reentrant structure are considered as part of a single group for deallocation purposes. Information associated with each cell specifies its group membership. Internal references (pointers from one cell of the group to another) are not reference counted. External references to any cell of this group are counted as references to the group as a whole. When the external reference count goes to zero, all the cells of the group can be deallocated. This paper describes several ways of specifying group membership, properties of each implementation, and properties of mutable and immutable group membership.  },
	Annote = {A set of design patterns used to circumvent the problem of circular data structures in reference counting environments.},
	Author = {Daniel G. Bobrow},
	Date-Modified = {2005-04-24 19:28:57 +0300},
	Doi = {http://doi.acm.org/10.1145/357103.357104},
	Issn = {0164-0925},
	Journal = {ACM Trans. Program. Lang. Syst.},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Managing%20Reentrant%20Structures%20Using%20Reference%20Counts.pdf},
	Number = {3},
	Pages = {269--273},
	Publisher = {ACM Press},
	Title = {Managing Reentrant Structures Using Reference Counts},
	Volume = {2},
	Year = {1980}}

@article{Linds81,
	Author = {Gary Lindstrom and Mary Lou Soffa},
	Date-Modified = {2005-03-02 16:32:25 +0200},
	Doi = {http://doi.acm.org/10.1145/357139.357143},
	Issn = {0164-0925},
	Journal = {ACM Trans. Program. Lang. Syst.},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Referencing%20and%20Retention%20in%20Block-Structured%20Coroutines.pdf},
	Number = {3},
	Pages = {263--292},
	Publisher = {ACM Press},
	Title = {Referencing and Retention in Block-Structured Coroutines},
	Volume = {3},
	Year = {1981}}

@inproceedings{Singe03,
	Abstract = {We present empirical evidence to demonstrate that there is little or no difference between the Java Virtual Machine and the .NET Common Language Runtime, as regards the compilation and execution of object-oriented programs. Then we give details of a case study that proves the superiority of the Common Language Runtime as a target for imperative programming language compilers (in particular GCC).},
	Annote = {Not exactly a study but a very priliminary result set of 4 Java benchmarks converted to C#. Performance is almost identical.},
	Author = {Jeremy Singer},
	Booktitle = {PPPJ '03: Proceedings of the 2nd international conference on Principles and practice of programming in Java},
	Date-Modified = {2005-02-28 14:42:50 +0200},
	Isbn = {0-9544145-1-9},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/JVM%20vs%20CLR%20-%20a%20comperative%20study.pdf},
	Location = {Kilkenny City, Ireland},
	Pages = {167--169},
	Publisher = {Computer Science Press, Inc.},
	Title = {JVM versus CLR: a comparative study},
	Year = {2003}}

@inproceedings{Gough01,
	Abstract = {A popular trend in current software technology is to gain program portability by compiling programs to an intermediate form based on an abstract machine definition. Such approaches date back at least to the 1970s, but have achieved new impetus based on the current popularity of the programming language Java. Implementations of language Java compile programs to bytecodes understood by the Java Virtual Machine (JVM). More recently Microsoft have released preliminary details of their ".NET" platform, which is based on an abstract machine superficially similar to the JVM. In each case program execution is normally mediated by a just in time compiler (JIT), although in principle interpretative execution is also possible.Although these two competing technologies share some common aims the objectives of the virtual machine designs are significantly different. In particular, the ease with which embedded systems might use small-footprint versions of these virtual machines depends on detailed properties of the machine definitions.In this study, a compiler was implemented which can produce output code that may be run on either the JVM or .NET platforms. The compiler is available in the public domain, and facilitates comparisons to be made both at compile time and at runtime.},
	Annote = {Compares the 2 VMs in terms of design goals, implementation details and multilanguage support. Reaches to the obvious conclusion that they are quite different in practice. Some challenges for the JVM is how to import language extensions to it (eg generics, },
	Author = {K John Gough},
	Booktitle = {ACSAC '01: Proceedings of the 6th Australasian conference on Computer systems architecture},
	Date-Modified = {2005-02-28 17:13:21 +0200},
	Isbn = {0-7695-0954-1},
	Location = {Queensland, Australia},
	Pages = {55--61},
	Publisher = {IEEE Computer Society},
	Title = {Stacking them up: a comparison of virtual machines},
	Year = {2001}}

@inproceedings{Hausw04,
	Abstract = {Object-oriented programming languages provide a rich set of features that provide significant software engineering benefits. The increased productivity provided by these features comes at a justifiable cost in a more sophisticated runtime system whose responsibility is to implement these features efficiently. However, the virtualization introduced by this sophistication provides a significant challenge to understanding complete system performance, not found in traditionally compiled languages, such as C or C++. Thus, understanding system performance of such a system requires profiling that spans all levels of the execution stack, such as the hardware, operating system, virtual machine, and application.

In this work, we suggest an approach, called <i>vertical profiling</i>, that enables this level of understanding. We illustrate the efficacy of this approach by providing deep understandings of performance problems of Java applications run on a VM with vertical profiling support. By incorporating vertical profiling into a programming environment, the programmer will be able to understand how their program interacts with the underlying abstraction levels, such as application server, VM, operating system, and hardware.},
	Author = {Matthias Hauswirth and Peter F. Sweeney and Amer Diwan and Michael Hind},
	Booktitle = {OOPSLA '04: Proceedings of the 19th annual ACM SIGPLAN Conference on Object-oriented programming, systems, languages, and applications},
	Date-Modified = {2005-02-14 18:25:41 +0200},
	Doi = {http://doi.acm.org/10.1145/1028976.1028998},
	Isbn = {1-58113-831-9},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Verical%20profiling.pdf},
	Location = {Vancouver, BC, Canada},
	Pages = {251--269},
	Publisher = {ACM Press},
	Title = {Vertical profiling: understanding the behavior of object-priented applications},
	Year = {2004}}

@article{Chang01,
	Abstract = {The object-oriented programming (OOP) language systems tend to perform object creation and deletion prolifically. An empirical study has shown that C++ programs can have 10 times more memory allocation and deallocation than comparable C programs. However, the allocation behavior of C++ programs is rarely reported. This paper attempts to locate where the dynamic memory allocations are coming from and report an empirical study of the allocation behavior of C++ programs. Firstly, this paper summarizes the hypothesis of situations that invoke the dynamic memory management explicitly and implicitly. They are: constructors, copy constructors, overloading assignment OPERATOR=, type conversions and application-specific member functions. Secondly, the development of a source code level tracing tool is reported as a procedure to investigate the hypothesis. Most of the five C++ programs traced are real-world applications. Thirdly, allocation patterns, object size and age distribution are summarized. Among other things, we found that objects tend to have a very short life-span, and most of them are created through constructors and copy constructors. With these findings, we may improve the performance of dynamic memory management through, a profile-based strategy or reusing objects.},
	Annote = {The authors argue that there are 4 cases for dynamic memory allocation in C++:
->Constructors
->Copy constructors
->Overloaded assignement operator (=)
->Transformations from user-defined types to basic types through the <operator type*()> construct. 
They instructed the gcc malloc code to report allocation and de-allocation requests and also instrumented the application code to report names of classes and functions that use the allocator. They found that object allocation and de-allocation time can range from 18% to 50% of total execution time. They confirmed the short-life object hypothesis and proposed object reuse for small objects.},
	Author = {J. Morris Chang and W.H. Lee and W. Srisa-an},
	Date-Modified = {2005-02-14 18:16:56 +0200},
	Journal = {Journal of Systems and Software},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20Study%20of%20the%20Allocation%20Behavior%20of%20C++%20Programs.pdf},
	Note = {accepted for publication, Fall 2001},
	Title = {A Study of the Allocation Behavior of {C++} Programs},
	Year = {2001}}

@article{Aycoc03,
	Abstract = {Software systems have been using "just-in-time" compilation (JIT) techniques since the 1960s. Broadly, JIT compilation includes any translation performed dynamically, after a program has started execution. We examine the motivation behind JIT compilation and constraints imposed on JIT compilation systems, and present a classification scheme for such systems. This classification emerges as we survey forty years of JIT work, from 1960--2000.},
	Annote = {This paper presents the JIT technology and how  has it been evolved throughout the years and applied on vatious programming languages. Also provides small classification of JIT systems in terms of common attributes such as Invocation, Executability and Concurency. Lots of references to pioneer work in the field of JIT.},
	Author = {John Aycock},
	Date-Modified = {2006-05-28 23:54:28 +0300},
	Doi = {http://doi.acm.org/10.1145/857076.857077},
	Issn = {0360-0300},
	Journal = {ACM Comput. Surv.},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20brief%20history%20of%20Just-In-Time.pdf},
	Number = {2},
	Pages = {97--113},
	Publisher = {ACM Press},
	Title = {A brief history of {J}ust-{I}n-{T}ime},
	Volume = {35},
	Year = {2003}}

@inproceedings{Black04-1,
	Abstract = {Increasingly popular languages such as Java and C# requireefficient garbage collection. This paper presents thedesign, implementation, and evaluation of MMTk, a MemoryManagement Toolkit for and in Java. MMTk is an efficient, composable, extensible, and portable framework for building garbage collectors. MMTk uses design patternsand compiler cooperation to combine modularity and efficiency. The resulting system is more robust, easier to maintain, and has fewer defects than monolithic collectors. Experimentalcomparisons with monolithic Java and C implementationsreveal MMTk has significant performance advantagesas well. Performance critical system software typicallyuses monolithic C at the expense of flexibility. Our resultsrefute common wisdom that only this approach attainsefficiency, and suggest that performance critical softwarecan embrace modular design and high-level languages.},
	Annote = {Describes the design and implementation of the MMTk for JikesRVM. MMTk is a suite of garbage collection algorithms that is able to build collectors through the composition of policies(mark-sweep, refcounting) and mechanisms(bumper pointer allocation, free list allocation). Different policies can be mapped to different continuous regions of memory through plans. The performance is a little worse compared to monolithic collectors in microbenchmarks (~8%) but on application benchmarks MMTk is better (up to 20%). Interestingly, the (instructed) compiler-inlined version of MMTk is more than 60% faster than the GNU C calloc() function. In the most close comparison (MMTk mark-sweep no-inline vs C calloc()) the C implementation is only 6% faster. Lots of references on reference implementations of garbage collection algorithms.},
	Author = {Stephen M. Blackburn and Perry Cheng and Kathryn S. McKinley},
	Booktitle = {ICSE '04: Proceedings of the 26th International Conference on Software Engineering},
	Date-Modified = {2005-05-05 11:59:05 +0300},
	Isbn = {0-7695-2163-0},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Oil%20and%20Water%3F%20High%20Performance%20Garbage%20Collection%20in%20Java%20with%20MMTk.pdf},
	Pages = {137--146},
	Publisher = {IEEE Computer Society},
	Title = {Oil and {W}ater? {H}igh Performance Garbage Collection in {J}ava with {MMTk}},
	Year = {2004}}

@inproceedings{Woo-J04,
	Abstract = {In recent years server applications using Java become popular. However, they have different performance requirements from other applications: high throughput and small response time. One of obstacles for achieving those requirements is a Java Virtual Machine (JVM). Among the services that a JVM provides, garbage collection affects server applications in throughput and latency. Some JVMs have various garbage collectors for server-side Java but they do not still consider the behavior of server applications. We show that the lifetime pattern of objects is distinguished by the thread that allocates them in server applications. Separating objects and applying different collection policies according to threads, we propose that a garbage collector can achieve both high throughput and small pause time. Experiments show that the throughput of our collector is up to 1.7 times greater than that of previous generational collectors with the same pause time and the pause time of minor collection is smaller by almost 10% given the same throughput},
	Address = {Tokyo, Japan},
	Annote = {The authors descibe a garbage collector that is implemented having a common server application architectural pattern in mind (coordinator-worker threads). The hypothesis presented is that coordinator threads generaly create large long-lived objects while worker threads  Upon creation each thread notifies the GC about its behaviour. The GC is a mark-sweep mature space generational collector with 2 variations of fixed or variable size nursery. The large object nursury is fixed size. The GC has a throughput og 1.2-1.7 times using the SPECweb benchmark on a specially modified web-server, while pause times are less or equal to the default (MS mature space, generational GC with fixed nursery size) GC of JikesRVM.},
	Author = {Woo Jin Kim and Kyungbaek Kim and Han, J.; Park, K. and Park, D.},
	Booktitle = {2004 International Symposium on Applications and the Internet},
	Date-Modified = {2005-03-01 20:55:02 +0200},
	Month = {January},
	Pages = {81--87},
	Title = {Thread-aware garbage collection for server applications},
	Year = {2004}}

@phdthesis{Zorn89,
	Annote = {Describes the 4 most basic algorithms for garbage collection. Uses a LISP environment to test the performance of their implementation under real application workload. Very good descriptions of the algorithms and the metrics used. },
	Author = {Benjamin Goth Zorn},
	Date-Modified = {2005-02-01 13:07:09 +0200},
	Order_No = {AAI9029086},
	School = {University of California at Berkeley},
	Title = {Comparative performance evaluation of garbage collection algorithms},
	Year = {1989}}

@inproceedings{Cheng01,
	Abstract = {We describe a parallel, real-time garbage collector and present experimental results that demonstrate good scalability and good real-time bounds. The collector is designed for shared-memory multiprocessors and is based on an earlier collector algorithm [2], which provided fixed bounds on the time any thread must pause for collection. However, since our earlier algorithm was designed for simple analysis, it had some impractical features. This paper presents the extensions necessary for a practical implementation: reducing excessive interleaving, handling stacks and global variables, reducing double allocation, and special treatment of large and small objects. An implementation based on the modified algorithm is evaluated on a set of 15 SML benchmarks on a Sun Enterprise 10000, a 64-way UltraSparc-II multiprocessor. To the best of our knowledge, this is the first implementation of a parallel, real-time garbage collector.

The average collector speedup is 7.5 at 8 processors and 17.7 at 32 processors. Maximum pause times range from 3 ms to 5 ms. In contrast, a non-incremental collector (whether generational or not) has maximum pause times from 10 ms to 650 ms. Compared to a non-parallel, stop-copy collector, parallelism has a 39% overhead, while real-time behavior adds an additional 12% overhead. Since the collector takes about 15% of total execution time, these features have an overall time costs of 6% and 2%.},
	Annote = {The authors describe a parallel, incremental and concurrent copying garbage collector which uses load balancing via sharing object lists. The objects accessed by the collector are stored in per processor stacks parts of which are periodically uploaded to a shared stack. They evaluate its performance on a shared memory multiprocessor and find significant gains from parallel operation and also find that operation is almost real time with pause times of 3 to 5 milliseconds constant.},
	Author = {Perry Cheng and Guy E. Blelloch},
	Booktitle = {PLDI '01: Proceedings of the ACM SIGPLAN 2001 conference on Programming language design and implementation},
	Date-Modified = {2005-03-20 21:29:47 +0200},
	Doi = {http://doi.acm.org/10.1145/378795.378823},
	Isbn = {1-58113-414-2},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20parallel,%20real-time%20garbage%20collector.pdf},
	Location = {Snowbird, Utah, United States},
	Pages = {125--136},
	Publisher = {ACM Press},
	Title = {A parallel, real-time garbage collector},
	Year = {2001}}

@inproceedings{Yang02,
	Abstract = {The performance issues of garbage collection (GC) have been studied for over three decades. This paper uses a new cycle accurate timing tool to measure GC metrics such as allocation latencies, component elapse time (mark, sweep, and compact) and object life span. The data are then used to derive runtime heap residency and overall GC time. In the past, researchers study object life span through a space based approach, where the amount of allocated memory determines GC invocations. We propose a tune based methodology as a complement. Time plays an important role in server environments, where allocations can come in bursts. The experimental results indicate that a time based approach yields significantly less GC calls, while maintains almost the same heap residency as the space based approach. This translates to a more efficient way to collect garbage},
	Address = {Phoenix, AZ, USA},
	Annote = {The authors study Java object lifespan as a function of both time and space. They argue that garbage collector invokation should occur both in regular time intervals and when space usage exceeds a threshold. They run the SpecJVM benchmark twice using either a fixed time interval for running the garbage collector or a fixed amount of allocated space and compare the object life cycle in both approaches. They also study the heap size in connection with the number of garbage garbage collections for both approaches. They find out that the time based approach yields to less garbage collection cycles while maintaining the same heap size for most benchmarks. They also present a table containing the workload distribution values for the Hotspot JVM 1.2.2. In some tests the garbage collection load can be as much as 53% with an average of 20%!},
	Author = {Qian Yang and Witawas Srisa-an and Skotiniotis, T. and Chang, J.M.},
	Booktitle = {Conference Proceedings of the 2002 IEEE International Performance, Computing, and Communications Conference},
	Date-Modified = {2005-02-14 16:01:58 +0200},
	Month = {April},
	Pages = {73--80},
	Title = {Java virtual machine timing probes: a study of object life span and garbage collection},
	Year = {2002}}

@inproceedings{Dykst02,
	Abstract = {Sun Microsystems introduced the Java HotSpot Virtual Machine as a high performance engine for the Java programming language. The improvements over the classic Java Virtual Machine include dynamic compilation and optimization, better thread synchronization, and a more sophisticated and fully accurate garbage collection system. In this paper, a thorough analysis of the dynamic memory management issues in the HotSpot VM are performed. The analysis includes the memory allocation latency, the workload distribution, overall garbage collection time, and the pause times. The results indicate that the HotSpot VM succeeds in reducing the pause times by approximately 80%. However, it may prolong the overall garbage collection time in some applications},
	Address = {Phoenix, AZ, USA},
	Annote = {Describes the implementation of the Hotspot's GC. Uses 2 generations. The young generation is divided in 3 spaces, the eden space where new objects are allocated between collections and from-to spaces where surviving objects are stored in a mark-compact scheme. The mature generation uses the train algorithm to store objects. The GC is compared to the classic JVM GC using the SPECjvm benchmarks. Pause times and allocation times are significantly reduced, but in general more total time is required for GC.},
	Author = {Dykstra, L. and Srisa-an, W. and Chang, J.M.},
	Booktitle = {Conference Proceedings of the IEEE International Performance, Computing, and Communications Conference},
	Date-Modified = {2005-03-01 21:53:30 +0200},
	Month = {April},
	Pages = {335--339},
	Title = {An analysis of the garbage collection performance in Sun's HotSpot Java Virtual Machine},
	Year = {2002}}

@article{Sugan00,
	Abstract = {We present the design and implementation of several optimizations and techniques included in the latest IBM JavaTM Just-in-Time (JIT) Compiler. We first discuss some of the modifications we have applied to Sun Microsystems' reference implementation of the Java Virtual Machine (JVMTM) Specification to increase the performance, including a change in the object layout. We then describe each of the optimizations, referring to what had to be taken into account because of both the just-in-time nature of the compiler and the requirements of the Java language specification, such as exception checking. We also present code generation techniques targeting Intel architectures, describing the register allocation schemes, exception handling, and code scheduling. Finally we report on the performance of the IBM JIT compiler, showing both the effectiveness of the individual optimizations and the competitive overall performance of the JIT compiler in comparison with a competitor, using industry-standard benchmarking programs. All the techniques presented here are included in the official product (JIT Compiler version 3.0), which has been integrated into the IBM Developer Kit for WindowsTM, Java Technology Edition, Version 1.1.7.},
	Annote = {The paper presents the first version of the IBM VM and the optimisations that have been implemented for it. Optimisations such as method inlining, exception check elimination, common subexpression elimination and loop versioning are explained(+ alternative implementations). Various other optimisations taking place during the code generation phase are then explained, such as register allocation, bytecode sequence idioms, type inclusion tests, code scheduling and exception handling (using hardware exceptions) are illustrated. A good paper for introductions on these optimisation techniques.},
	Author = {T. Suganuma and T. Ogasawara and M. Takeuchi and T. Yasue and M. Kawahito and K. Ishizaki and H. Komatsu and T. Nakatani},
	Date-Modified = {2005-01-31 15:54:45 +0200},
	Issn = {0018-8670},
	Journal = {IBM Syst. J.},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Overview%20of%20the%20IBM%20Java%20just-in-time%20compiler.pdf},
	Number = {1},
	Pages = {175--193},
	Publisher = {IBM Corp.},
	Title = {Overview of the IBM Java just-in-time compiler},
	Volume = {39},
	Year = {2000}}

@inproceedings{Alper01,
	Abstract = {Single superclass inheritance enables simple and efficient table-driven virtual method dispathc. However, virtual method table dispatch does not handle multiple inheritance and interfaces. This complication has led to a widespread misimpression that interface method dispatch is inherently inefficient. This paper argues that with proper implementation techniques, Java interfaces need not be a source of significant performance degradation.},
	Annote = {First describes how is virtual method dispatch being performed in Java and then argues that an interface method invocation can be as much as 50 times slower than virtual method invocation. It goes on to present the available techniques for interface dispatch:
 =>Interface tables: Stores indexes to class-specific method implementations in tables (one for each implemented interface) reachable from the class object.
 =>Caching: Instead of searching the VMT for each invocation, cache last results and fall back to search on cache misses. Inline caching substitutes the method lookup function with the method last called from the specific caller (also falls back on miss). Polymorphic inline caches substitute method lookups with dynamically generated tests that identify whether the call matches previously seen calls.
 =>Selector Index Tables: Use method signatures to index methods and use special selectors to index implemented interface methods. Each class maintains a table indexed per selector. Implemented interface methods are pointed by table entries.
 The paper proposes a new interface dispatch method called Interface Method Table, which is sort of a derivative of Selector Index Tables with the addition of a mechanism to handle naming (color) collisions. The resulting implementation is only a few cycles slower than virtual method dispatching.},
	Author = {Bowen Alpern and Anthony Cocchi and Stephen Fink and David Grove},
	Booktitle = {OOPSLA '01: Proceedings of the 16th ACM SIGPLAN conference on Object oriented programming, systems, languages, and applications},
	Date-Modified = {2005-05-05 11:59:26 +0300},
	Doi = {http://doi.acm.org/10.1145/504282.504291},
	Isbn = {1-58113-335-9},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Efficient%20implementation%20of%20Java%20interfaces:%20Invokeinterface%20considered%20harmless.pdf},
	Location = {Tampa Bay, FL, USA},
	Pages = {108--124},
	Publisher = {ACM Press},
	Title = {Efficient implementation of {J}ava interfaces: Invokeinterface considered harmless},
	Year = {2001}}

@inproceedings{Radha01,
	Abstract = {State of the art Java Virtual Machines with Just-In-Time (JIT) compilers make use of advanced compiler techniques, run-time profiling and adaptive compilation to improve performance. However, these techniques for alleviating performance bottlenecks are more effective in long running workloads, such as server applications. Short running Java programs, or client workloads, spend a large fraction of their execution time in compilation instead of useful execution when run using JIT compilers. In short running Java programs, the benefits of runtime translation do not compensate for the overhead.

We propose using hardware support to perform efficient Java translation coupled with a light weight run time environment. The additional hardware performs the translation of Java bytecodes to native code, thus eliminating much of the overhead of software translation. A translate d code buffer is used to hold the translated code, enabling reuse at the byte code level. The proposed hardware can be used in any general purpose processor without degrading performance of native code. The proposed technique is extremely effective for short running client workloads. A performance improvement of 2.8 times to 7.7 times over a software interpreter is achieved. When compared to a JIT compiler all SPECjvm98 benchmarks except one show a performance improvement ranging from. 2.7 times to 5.0 times. A performance degradation (0.58 times) is observed for one benchmark which is long running. Allowing hardware translation to perform optimizations similar to JIT compilers and Java processors will execute long running programs more efficiently and provide speedups similar to that of client workloads.},
	Annote = {Describes the design of the Hard-Int Java acceleration architecture. The chip translates bytecodes directly to machine specific native code. The chip provides a significant speedup for 'client-like' workloads (one time runs). The benchmarking methodology is quite weak though as their chip simulator only translates bytecodes and try to emulate a full VM by means of VM-like JNI calls. They reach to the conclusion that Java chips should be embeded to general purpose CPUs as e.g. MMX did. Not a terribly convincing paper, but a good source of references on Java hardware.},
	Author = {Ramesh Radhakrishnan and Ravi Bhargava and Lizy K. John},
	Booktitle = {ICS '01: Proceedings of the 15th international conference on Supercomputing},
	Date-Modified = {2005-01-31 13:53:05 +0200},
	Doi = {http://doi.acm.org/10.1145/377792.377901},
	Isbn = {1-58113-410-X},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Improving%20Java%20performance%20using%20hardware%20translation.pdf},
	Location = {Sorrento, Italy},
	Pages = {427--439},
	Publisher = {ACM Press},
	Title = {Improving Java performance using hardware translation},
	Year = {2001}}

@inproceedings{Detle99,
	Abstract = {We discuss aspects of inlining of virtual method invocations. First, we introduce a new method test to guard inlinings of such invocations, with a different set of tradeoffs from the class-equality tests proposed previously in the literature. Second, we consider the problem of inlining virtual methods directly, with no guarding test, in dynamic languages such as Self or the Java programming language, whose semantics prohibit a static identification of the complete set of modules that comprise a program. In non-dynamic languages, a whole-program analysis might prove the correctness of a direct virtual inlining. In dynamic languages, however, such analyses can be invalidated by later class loading, and must therefore be treated as assumptions whose later violation must cause recompilation. In the past, such systems have required an on-stack replacement mechanism to update currently-executing invocations of methods containing invalidated inlinings. This paper presents analyses that allow some virtual calls to be inlined directly, while ensuring that invocations in progress may complete safely even if class loading invalidates the inlining for future invocations. This provides the benefits of direct inlining without the need for on-stack replacement, which can be complicated and require space-consuming data structures.
  },
	Author = {David Detlefs and Ole Agesen},
	Booktitle = {ECOOP '99: Proceedings of the 13th European Conference on Object-Oriented Programming},
	Date-Modified = {2005-01-31 13:53:12 +0200},
	Isbn = {3-540-66156-5},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Inlining%20of%20Virtual%20Methods.pdf},
	Pages = {258--278},
	Publisher = {Springer-Verlag},
	Title = {Inlining of Virtual Methods},
	Year = {1999}}

@inproceedings{Ishiz00,
	Abstract = {Many devirtualization techniques have been proposed to reduce the runtime overhead of dynamic method calls for various objectoriented languages, however, most of them are less effective or cannot be applied for Java in a straightforward manner. This is partly because Java is a statically-typed language and thus transforming a dynamic call to a static one does not make a tangible performance gain (owing to the low overhead of accessing the method table) unless it is inlined, and partly because the dynamic class loading feature of Java prohibits the whole program analysis and optimizations from being applied. 
 
 We propose a new technique called direct devirtualization with the code patching mechanism. For a given dynamic call site, our compiler first determines whether the call can be devirtualized, by analyzing the current class hierarchy. When the call is devirtualizable and the target method is suitably sized, the compiler generates the inlined code of the method, together with the backup code of making the dynamic call. Only the inlined code is actually executed until our assumption about the devirtualization becomes invalidated, at which time the compiler performs code patching to make the backup code executed subsequently. Since the new technique prevents some code motions across the merge point between the inlined code and the backup code, we have furthermore implemented recently-known analysis techniques, such as type analysis and preexistence analysis, which allow the backup code to be completely eliminated. We made various experiments using 16 real programs to understand the effectiveness and characteristics of the devirtualization techniques in our Java Just-In- Time (JIT) compiler. In summary, we reduced the number of dynamic calls by ranging from 8.9% to 97.3% (the average of 40.2%), and we improved the execution performance by ranging from -1% to 133% (with the geometric mean of 16%). specific permission and/or a fee.},
	Author = {Kazuaki Ishizaki and Motohiro Kawahito and Toshiaki Yasue and Hideaki Komatsu and Toshio Nakatani},
	Booktitle = {OOPSLA '00: Proceedings of the 15th ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
	Date-Modified = {2005-05-05 11:59:20 +0300},
	Doi = {http://doi.acm.org/10.1145/353171.353191},
	Isbn = {1-58113-200-X},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20study%20of%20devirtualization%20techniques%20for%20a%20Java%20Just-In-Time%20compiler.pdf},
	Location = {Minneapolis, Minnesota, United States},
	Pages = {294--310},
	Publisher = {ACM Press},
	Title = {A study of devirtualization techniques for a {J}ava {Just-In-Time} compiler},
	Year = {2000}}

@url{Krint05,
	Annote = {Introductory presentations in many modern programming language's internals (type systems, runtime implementation, dynamic dispatch and optimisations, profiling)},
	Author = {Chandra Krintz},
	Date-Added = {2005-01-27 17:03:45 +0200},
	Date-Modified = {2005-01-27 17:11:50 +0200},
	Title = {CS263 - Implementations of Modern Programming Languages},
	Url = {http://www.cs.ucsb.edu/~ckrintz/classes/w05/cs263/index.html},
	Urldate = {01/2005}}

@inproceedings{Bacon02,
	Abstract = {While many object-oriented languages impose space overhead of only one word per object to support features like virtual method dispatch, Java's richer functionality has led to implementations that require two or three header words per object. This space overhead increases memory usage and attendant garbage collection costs, reduces cache locality, and constrains programmers who might naturally solve a problem by using large numbers of small objects. In this paper, we show that with careful engineering, a high-performance virtual machine can instantiate most Java objects with only a single-word object header. The single header word provides fast access to the virtual method table, allowing for quick method invocation. The implementation represents other per-object data (lock state, hash code, and garbage collection flags) using heuristic compression techniques. The heuristic retains two-word headers, containing thin lock state, only for objects that have synchronized methods. We describe the implementation of various object models in the IBM Jikes Research Virtual Machine, by introducing a pluggable object model abstraction into the virtual machine implementation. We compare an object model with a twoword header with three different object models with single-word headers. Experimental results show that the object header compression techniques give a mean space savings of 7%, with savings of up to 21%. Compared to the two-word headers, the compressed space-encodings result in application speedups ranging from to . Performance on synthetic micro-benchmarks ranges from due to benefits from reduced object size, to on a stress test of virtual method invocation. },
	Annote = {The paper describes the implementation of the Java runtime object model in the JikesRVM. The authors used various techniques for compressing a runtime object's headers, mainly affecting the space reserved for locks and the TIB pointer. They introduced a pluggable object model implementation and implemented two variations of it using single and double word object headers. They conducted a long list of experiments reaching to the conclusion that the proposed one-word header object model does not hurt performance (from -1,9% to +2,3% in various experiments) while saving a significant amount of space (from 7% to 21%). The paper provides a good description of a typical Java runtime object model.},
	Author = {David F. Bacon and Stephen J. Fink and David Grove},
	Booktitle = {ECOOP '02: Proceedings of the 16th European Conference on Object-Oriented Programming},
	Date-Modified = {2005-05-05 12:00:09 +0300},
	Isbn = {3-540-43759-2},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Space-%20and%20Time-Efficient%20Implementation%20of%20the%20Java%20Object%20Model.ps},
	Pages = {111--132},
	Publisher = {Springer-Verlag},
	Title = {Space- and {T}ime-Efficient Implementation of the {J}ava Object Model},
	Year = {2002}}

@url{Bachr05,
	Annote = {Presentations and tons of references on runtime implementation of object oriented languages},
	Author = {Jonathan Bachrach},
	Date-Added = {2005-01-27 17:03:45 +0200},
	Date-Modified = {2005-01-27 17:11:50 +0200},
	Title = {6.894 Object-Oriented Dynamic Languages},
	Url = {http://www.ai.mit.edu/projects/dynlangs/oodl-course/spring01/},
	Urldate = {01/2005}}

@inproceedings{Huang04,
	Abstract = {As improvements in processor speed continue to outpace improvements in cache and memory speed, poor locality increasingly degrades performance. Because copying garbage collectors move objects, they have an opportunity to improve locality. However, no static copying order is guaranteed to match program traversal orders. This paper introduces <i>online object reordering</i> (OOR) which includes a new dynamic, online class analysis for Java that detects program traversal patterns and exploits them in a copying collector. OOR uses run-time method sampling that drives just-in-time (JIT) compilation. For each <i>hot</i> (frequently executed) method, OOR analysis identifies the hot field accesses. At garbage collection time, the OOR collector then copies referents of hot fields together with their parent. Enhancements include static analysis to exclude accesses in cold basic blocks, heuristics that decay heat to respond to phase changes, and a separate space for hot objects. The overhead of OOR is on average negligible and always less than 2% on Java benchmarks in Jikes RVM with MMTk. We compare program performance of OOR to static class-oblivious copying orders (e.g., breadth and depth first). Performance variation due to static orders is often low, but can be up to 25%. In contrast, OOR matches or improves upon the best static order since its history-based copying tunes memory layout to program traversal.

},
	Annote = {Describes the development of a GC for MMTk that exploits the performance data gathered by the adaptive compiler subsystem included in JikesRVM. The GC uses these data to identify "hot memory" regions and drives a generational copying collector. Hot memory is usualy fields which hot methods access. At GC time, the objects that refer to hot fields are copied at contiguous memory regions along with their parents. Since in principle generational collection is based on the fact that the number of accesses to an object is inverse proportional to its age, hot memory is much more likely to be accessed and in addition it is organised in a contiguous region. This fact seems to boost locality of reference and in turn CPU cache hit ratio. The authors show that this tecnhique provides equal or better results to mark-sweep GCs which produce malloc-like allocation patterns (i.e. fragmentation).},
	Author = {Xianglong Huang and Stephen M. Blackburn and Kathryn S. McKinley and J Eliot B. Moss and Zhenlin Wang and Perry Cheng},
	Booktitle = {OOPSLA '04: Proceedings of the 19th annual ACM SIGPLAN Conference on Object-oriented programming, systems, languages, and applications},
	Date-Modified = {2005-01-31 13:53:48 +0200},
	Doi = {http://doi.acm.org/10.1145/1028976.1028983},
	Isbn = {1-58113-831-9},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/The%20garbage%20collection%20advantage-%20improving%20program%20locality.pdf},
	Location = {Vancouver, BC, Canada},
	Pages = {69--80},
	Publisher = {ACM Press},
	Title = {The garbage collection advantage: improving program locality},
	Year = {2004}}

@inproceedings{Black04,
	Abstract = {This paper explores and quantifies garbage collection behavior for three whole heap collectors and generational counterparts: copying semi-space, mark-sweep, and reference counting, the canonical algorithms from which essentially all other collection algorithms are derived. Efficient implementations in MMTk, a Java memory management toolkit, in IBM's Jikes RVM share all common mechanisms to provide a clean experimental platform. Instrumentation separates collector and program behavior, and performance counters measure timing and memory behavior on three architectures.Our experimental design reveals key algorithmic features and how they match program characteristics to explain the direct and indirect costs of garbage collection as a function of heap size on the SPEC JVM benchmarks. For example, we find that the contiguous allocation of copying collectors attains significant locality benefits over free-list allocators. The reduced collection costs of the generational algorithms together with the locality benefit of contiguous allocation motivates a copying nursery for newly allocated objects. These benefits dominate the overheads of generational collectors compared with non-generational and no collection, disputing the myth that "no garbage collection is good garbage collection." Performance is less sensitive to the mature space collection algorithm in our benchmarks. However the locality and pointer mutation characteristics for a given program occasionally prefer copying or mark-sweep. This study is unique in its breadth of garbage collection algorithms and its depth of analysis.},
	Annote = {Measures the performance of several garbage collection algorithms used for the JikesRVM MMTk on three architectures. Interesting observations:
->Performance impact of garbage collection is under-explored
->Contiguous memory allocation performs better than free-list like (i.e. malloc/free), and what's more architectural trends are expected to make this advantage bigger. This may mean that GC would actually perform better than malloc/free in the future.
},
	Author = {Stephen M. Blackburn and Perry Cheng and Kathryn S. McKinley},
	Booktitle = {SIGMETRICS 2004/PERFORMANCE 2004: Proceedings of the joint international conference on Measurement and modeling of computer systems},
	Date-Modified = {2005-01-31 13:53:22 +0200},
	Doi = {http://doi.acm.org/10.1145/1005686.1005693},
	Isbn = {1-58113-873-3},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Myths%20and%20realities-%20the%20performance%20impact%20of%20garbage%20collection.pdf},
	Location = {New York, USA},
	Pages = {25--36},
	Publisher = {ACM Press},
	Title = {Myths and realities: the performance impact of garbage collection},
	Year = {2004}}

@article{Kazi00,
	Abstract = {This survey describes research directions in techniques to improve the performance of programs written in the Java programming language. The standard technique for Java execution is interpretation, which provides for extensive portability of programs. A Java interpreter dynamically executes Java bytecodes, which comprise the instruction set of the Java Virtual Machine (JVM). Execution time performance of Java programs can be improved through compilation, possibly at the expense of portability. Various types of Java compilers have been proposed, including Just-In-Time (JIT) compilers that compile bytecode into native processor instructions on the fly; direct compilers that directly translate the Java source code into the target processor's native language; and bytecode-to-source translators that generate either native code or an intermediate language, such as C, from the bytecodes. Additional techniques, including bytecode optimization, dynamic compilation, and executing Java programs in parallel, attempt to improve Java run-time performance while maintaining Java's portability. Another alternative for executing Java programs is a Java processor that implements the JVM directly in hardware. In this survey, we discuss the basis features, and the advantages and disadvantages, of the various Java execution techniques. We also discuss the various Java benchmarks that are being used by the Java community for performance evaluation of the different techniques. Finally, we conclude with a comparison of the performance of the alternative Java execution techniques based on reported results.},
	Annote = {-Describes a general JVM
-Lists the alternative methods for executing bytecodes (interpreters, JITs, ,bytecode to C, Java Hardware Processors)
-Lists briefly possible optimisations performed by JITs and Java Compilers (a little outdated)
-High performance execution techniques:
	->Bytecode optimisation: Optimise size & order of execution in the bytecode.
	->Auto-parallelisation and distributed execution: Use Java semantics such as 	threads, locks to parallelise e.g. loops
	->Hotspot compilers: Only JIT compile hot code portions. Start execution with 	profiling interpreter and compile with every possible optimisation hot code.
	->Adaptive compilers: Start with bytecode->native code compiler using minimal or 	no optimisation, gather usage data, perform heavy optimisation when reaching a 	certain performance threshold
	->Fine grained locking, high performance libraries, optimised garbage collectors.
-Presents Java benchmarks that can be used.
-Presents results for some (ancient) virtual machines.},
	Author = {Iffat H. Kazi and Howard H. Chen and Berdenia Stanley and David J. Lilja},
	Date-Modified = {2005-05-05 11:58:39 +0300},
	Doi = {http://doi.acm.org/10.1145/367701.367714},
	Issn = {0360-0300},
	Journal = {ACM Comput. Surv.},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/Techniques%20for%20obtaining%20high%20performance%20in%20Java%20programs.pdf},
	Number = {3},
	Pages = {213--240},
	Publisher = {ACM Press},
	Title = {Techniques for obtaining high performance in {J}ava programs},
	Volume = {32},
	Year = {2000}}

@article{Attan03,
	Abstract = {While uniprocessor garbage collection is relatively well understood, experience with collectors for large multiprocessor servers is limited and it is unknown which techniques best scale with large memories and large numbers of processors. In order to explore these issues we designed a modular garbage collection framework in the IBM Jalapeno Java virtual machine and implemented five different parallel garbage collectors: non-generational and generational versions of mark-and-sweep and semi-space copying collectors, as well as a hybrid of the two. We describe the optimizations necessary to achieve good performance across all of the collectors, including load balancing, fast synchronization, and inter-processor sharing of free lists. We then quantitatively compare the different collectors to find their asymptotic performance both with respect to how fast they can run applications as well as how little memory they can run them in. All of our collectors scale linearly up to sixteen processors. The least memory is usually required by the hybrid mark-sweep collector that uses a copying collector for its nursery, although sometimes the non-generational mark-sweep collector requires less memory. The fastest execution is more application-dependent. Our only application with a large working set performed best using the mark-sweep collector; with one exception, the rest of the applications ran fastest with one of the generational collectors.},
	Annote = {The authors benchmark 4 garbage collector implementations on a 16 processor machine using (among others) the TCP-P benchmark. They find that the mark-sweep collector outperforms competitors when memory is tight. The copying collector offers its best performance when the object generation rate is high and their lifes are short. Generational collectors perform best when (as expected) using large sets of objects and at least some of them are long-lived. Finally, the best overall performace is provided by the hybrid (mark sweep for mature space and semi-space copying for the nursery) collector especialy under memory constraints. },
	Author = {Clement R. Attanasio and David F. Bacon and Anthony Cocchi and Stephen Smith},
	Date-Added = {2005-01-19 11:38:52 +0200},
	Date-Modified = {2005-01-31 16:33:16 +0200},
	Journal = {Lecture Notes in Computer Science},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/A%20Comparative%20Evaluation%20of%20Parallel%20Garbage%20Collector%20Implementations.pdf},
	Month = {January},
	Pages = {177-192},
	Title = {A Comparative Evaluation of Parallel Garbage Collector Implementations},
	Volume = {2624},
	Year = {2003}}

@periodical{Doede03,
	Abstract = {The Java platform introduced Virtual Machines, JIT Compilers and Garbage Collectors to the masses and to mainstream software development. Demand and competition drove impressive improvements in the performance of Java implementations, and while the state of the art can be learned from JVM research papers and product benchmarks, we offer a ``Making Of'' exposing the challenges, tensions and strategies behind this history, extrapolating to similar platforms such as Microsoft .NET's CLR.},
	Annote = {Provides a narative chronological review of advances in Java performance practices and provides a fairly good comparison with .NET. Good starting point, lots of references to scientific work. It is quite up-to-date.},
	Author = {Osvaldo Doederlein},
	Date-Added = {2005-01-18 13:25:25 +0200},
	Date-Modified = {2005-05-05 11:59:49 +0300},
	Journal = {Journal of Object Technology},
	Local-Url = {file://localhost/Volumes/Files/Documents/PhD/papers/OO%20lang%20performance/The%20Tale%20of%20Java%20Performance.pdf},
	Pages = {17-40},
	Title = {The Tale of {J}ava Performance},
	Url = {http://www.jot.fm/issues/issue_2003_09/column3},
	Volume = {2},
	Year = {2003}}

@url{Techn,
	Annote = {Nice site with lots of info on memory management and garbage collection},
	Author = {{GC} {T}echnique},
	Date-Added = {2005-01-19 17:03:45 +0200},
	Date-Modified = {2005-01-31 13:34:30 +0200},
	Title = {The Memory Management Reference Bibliography},
	Url = {http://www.memorymanagement.org/},
	Urldate = {01/2005}}
