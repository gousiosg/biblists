@article{KGS22,
  author   = {Kotti, Zoe and Gousios, Georgios and Spinellis, Diomidis},
  journal  = {IEEE Transactions on Software Engineering},
  title    = {Impact of Software Engineering Research in Practice: A Patent and Author Survey Analysis},
  year     = {2022},
  volume   = {},
  number   = {},
  pages    = {1-19},
  doi      = {10.1109/TSE.2022.3208210},
  abstract = {
              Existing work on the practical impact of software engineering (SE) research examines
              industrial relevance rather than adoption of study results, hence the question of
              how results have been practically applied remains open. To answer this and
              investigate the outcomes of impactful research, we performed a quantitative and
              qualitative analysis of 4,354 SE patents citing 1,690 SE papers published in four
              leading SE venues between 1975–2017. Moreover, we conducted a survey on 475 authors
              of 593 top-cited and awarded publications, achieving 26% response rate. Overall,
              researchers have equipped practitioners with various tools, processes, and methods,
              and improved many existing products. SE practice values knowledge-seeking research
              and is impacted by diverse cross-disciplinary SE areas. Practitioner-oriented
              publication venues appear more impactful than researcher-oriented ones, while
              industry-related tracks in conferences could enhance their impact. Some research
              works did not reach a wide footprint due to limited funding resources or unfavorable
              cost-benefit trade-off of the proposed solutions. The need for higher SE research
              funding could be corroborated through a dedicated empirical study. In general, the
              assessment of impact is subject to its definition. Therefore, academia and industry
              could jointly agree on a formal description to set a common ground for subsequent
              research on the topic.
  },
  url       = {https://arxiv.org/pdf/2204.03366.pdf}
}


@article{MUBNGD22,
  author    = {Maddila, Chandra and Upadrasta, Sai Surya and Bansal, Chetan and Nagappan, Nachiappan and Gousios, Georgios and Deursen, Arie van},
  title     = {Nudge: Accelerating Overdue Pull Requests Towards Completion},
  year      = {2022},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  issn      = {1049-331X},
  url       = {https://doi.org/10.1145/3544791},
  doi       = {10.1145/3544791},
  journal   = {ACM Trans. Softw. Eng. Methodol.},
  month     = {may},
  keywords  = {distributed software development, Pull-based software development, merge conflict, pull request},
  abstract  = {
              Pull requests are a key part of the collaborative software development and code review
              process today. However, pull requests can also slow down the software development
              process when the reviewer(s) or the author do not actively engage with the pull
              request. In this work, we design an end-to-end service, Nudge, for accelerating overdue
              pull requests towards completion by reminding the author or the reviewer(s) to engage
              with their overdue pull requests. First, we use models based on effort estimation and
              machine learning to predict the completion time for a given pull request. Second, we
              use activity detection to filter out pull requests that may be overdue, but for which
              sufficient action is taking place nonetheless. Lastly, we use actor identification to
              understand who the blocker of the pull request is and nudge the appropriate actor
              (author or reviewer(s)). The key novelty of Nudge is that it succeeds in reducing
              pull request resolution time, while ensuring that developers perceive the notifications
              sent as useful, at the scale of thousands of repositories. In a randomized trial on
              147 repositories in use at Microsoft, Nudge was able to reduce pull request resolution
              time by 60% for 8,500 pull requests, when compared to overdue pull requests for which
              Nudge did not send a notification. Furthermore, developers receiving Nudge notifications
              resolved 73% of these notifications as positive. We observed similar results when scaling
              up the deployment of Nudge to 8,000 repositories at Microsoft, for which Nudge sent
              210,000 notifications during a full year. This demonstrates Nudge's ability to scale
              to thousands of repositories. Lastly, our qualitative analysis of a selection of
              Nudge notifications indicates areas for future research, such as taking dependencies
              among pull requests and developer availability into account.
               },
  url       = {https://arxiv.org/pdf/2011.12468.pdf}
}

@article{ZTGR22,
  author   = {Zhang, Xunhui and Yu, Yue and Georgios, Gousios and Rastogi, Ayushi},
  journal  = {IEEE Transactions on Software Engineering},
  title    = {Pull Request Decisions Explained: An Empirical Overview},
  year     = {2022},
  volume   = {},
  number   = {},
  pages    = {1-1},
  doi      = {10.1109/TSE.2022.3165056},
  abstract = {
              Context: Pull-based development model is widely used in open source, leading the trends
              in distributed software development. One aspect which has garnered significant attention
              is studies on pull request decision - identifying factors for explanation. Objective:
              This study builds on a decade long research on pull request decision to explain it.
              We empirically investigate how factors influence pull request decision and scenarios
              that change the influence of factors. Method: We identify factors influencing pull request
              decision on GitHub through a systematic literature review and infer it by mining
              archival data. We collect a total of 3,347,937 pull requests with 95 features from
              11,230 diverse projects on GitHub. Using this data, we explore the relations of the
              factors to each other and build mixed-effect logistic regression models to empirically
              explain pull request decision. Results: Our study shows that a small number of factors
              explain pull request decision with the integrator same or different from the submitter
              as the most important factor. We also noted that some factors are important only in special
              cases e.g., the percentage of failed builds is important for pull request decision when
              continuous integration is used.
              },
  url      = {https://arxiv.org/pdf/2105.13970.pdf}
}

@article{HG22,
  title    = {Can we trust tests to automate dependency updates? A case study of Java Projects},
  journal  = {Journal of Systems and Software},
  volume   = {183},
  pages    = {111097},
  year     = {2022},
  issn     = {0164-1212},
  doi      = {https://doi.org/10.1016/j.jss.2021.111097},
  author   = {Joseph Hejderup and Georgios Gousios},
  keywords = {Semantic versioning, Library updates, Package management, Dependency management, Software migration},
  abstract = {
              Developers are increasingly using services such as Dependabot to automate
              dependency updates. However, recent research has shown that developers
              perceive such services as unreliable, as they heavily rely on test coverage
              to detect conflicts in updates. To understand the prevalence of tests
              exercising dependencies, we calculate the test coverage of direct and
              indirect uses of dependencies in 521 well-tested Java projects. We find that
              tests only cover 58% of direct and 21% of transitive dependency calls. By
              creating 1,122,420 artificial updates with simple faults covering all
              dependency usages in 262 projects, we measure the effectiveness of test
              suites in detecting semantic faults in dependencies; we find that tests can
              only detect 47% of direct and 35% of indirect artificial faults on average.
              To increase reliability, we investigate the use of change impact analysis as
              a means of reducing false negatives; on average, our tool can uncover 74% of
              injected faults in direct dependencies and 64% for transitive dependencies,
              nearly two times more than test suites. We then apply our tool in 22
              real-world dependency updates, where it identifies three semantically
              conflicting cases and three cases of unused dependencies that tests were
              unable to detect. Our findings indicate that the combination of static and
              dynamic analysis should be a requirement for future dependency updating
              systems.
              },
  url      = {https://arxiv.org/pdf/2109.11921.pdf},
  github   = {jhejderup/uppdatera}
}

@misc{HBTG22,
  title    = {Pr\"azi: From Package-based to Call-based Dependency Networks},
  author   = {Joseph Hejderup and Moritz Beller and Konstantinos Triantafyllou and Georgios Gousios},
  journal  = {Empirical Software Engineering},
  volume   = {27},
  number   = {5},
  pages    = {1--42},
  year     = {2022},
  doi      = {10.1007/s10664-021-10071-9},
  abstract = {
              Modern programming languages such as Java, JavaScript, and Rust
              encourage software reuse by hosting diverse and fast-growing repositories of
              highly interdependent packages (i.e., reusable libraries) for their users. The
              standard way to study the interdependence between software packages is to infer
              a package dependency network by parsing manifest data. Such networks help answer
              questions such as "How many packages have dependencies to packages with known
              security issues?” or “What are the most used packages?". However, an overlooked
              aspect in existing studies is that manifest-inferred relationships do not
              necessarily examine the actual usage of these dependencies in source code. To
              better model dependencies between packages, we developed Präzi, an approach
              combining manifests and call graphs of packages. Präzi constructs a dependency
              network at the more fine-grained function-level, instead of at the manifest
              level. This paper discusses a prototypical Präzi implementation for the
              popular system programming language Rust. We use Präzi to characterize Rust’s
              package repository, Crates.io, at the function level and perform a comparative
              study with metadata-based networks. Our results show that metadata-based
              networks generalize how packages use their dependencies.

              Using Using Präzi, we find packages call only 40% of their resolved dependencies,
              and that manual analysis of 34 cases reveals that not all packages use a dependency
              the same way. We argue that researchers and practitioners interested in understanding
              how developers or programs use dependencies should account for its context—not the
              sum of all resolved dependencies., we find packages call only 40% of their resolved
              dependencies, and that manual analysis of 34 cases reveals that not all packages
              use a dependency the same way. We argue that researchers and practitioners interested
              in understanding how developers or programs use dependencies should account for its
              context—not the sum of all resolved dependencies.
              },
  github   = {jhejderup/prazi},
  url      = {https://arxiv.org/pdf/2101.09563.pdf}
}

@article{KGDG21,
  author   = {Kula, Elvan and Greuter, Eric and Van Deursen, Arie and Georgios, Gousios},
  journal  = {IEEE Transactions on Software Engineering},
  title    = {Factors Affecting On-Time Delivery in Large-Scale Agile Software Development},
  year     = {2021},
  volume   = {48},
  number   = {9},
  pages    = {3573-3592},
  doi      = {10.1109/TSE.2021.3101192},
  abstract = {
              Late delivery of software projects and cost overruns have been common
              problems in the software industry for decades. Both problems are
              manifestations of deficiencies in effort estimation during project planning.
              With software projects being complex socio-technical systems, a large pool
              of factors can affect effort estimation and on-time delivery. To identify
              the most relevant factors and their interactions affecting schedule
              deviations in large-scale agile software development, we conducted a
              mixed-methods case study at ING: two rounds of surveys revealed a multitude
              of organizational, people, process, project and technical factors which were
              then quantified and statistically modeled using software repository data
              from 185 teams. We find that factors such as requirements refinement, task
              dependencies, organizational alignment and organizational politics are
              perceived to have the greatest impact on on-time delivery, whereas proxy
              measures such as project size, number of dependencies, historical delivery
              performance and team familiarity can help explain a large degree of schedule
              deviations. We also discover hierarchical interactions among factors:
              organizational factors are perceived to interact with people factors, which
              in turn impact technical factors. We compose our findings in the form of a
              conceptual framework representing influential factors and their
              relationships to on-time delivery. Our results can help practitioners
              identify and manage delay risks in agile settings, can inform the design of
              automated tools to predict schedule overruns and can contribute towards the
              development of a relational theory of software project management.
              },
  url      = {https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9503331}
}

@article{MNBGD21,
  author     = {Maddila, Chandra and Nagappan, Nachiappan and Bird, Christian and Gousios, Georgios and van Deursen, Arie},
  title      = {ConE: A Concurrent Edit Detection Tool for Large-Scale Software Development},
  year       = {2021},
  issue_date = {April 2022},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {31},
  number     = {2},
  issn       = {1049-331X},
  doi        = {10.1145/3478019},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  month      = {dec},
  articleno  = {22},
  numpages   = {26},
  abstract   = {
                Modern, complex software systems are being continuously extended and
                adjusted. The developers responsible for this may come from different teams
                or organizations, and may be distributed over the world. This may make it
                difficult to keep track of what other developers are doing, which may result
                in multiple developers concurrently editing the same code areas. This, in
                turn, may lead to hard-to-merge changes or even merge conflicts, logical
                bugs that are difficult to detect, duplication of work, and wasted developer
                productivity. To address this, we explore the extent of this problem in the
                pull request based software development model. We study half a year of
                changes made to six large repositories in Microsoft in which at least 1,000
                pull requests are created each month. We find that files concurrently edited
                in different pull requests are more likely to introduce bugs. Motivated by
                these findings, we design, implement, and deploy a service named ConE
                (Concurrent Edit Detector) that proactively detects pull requests containing
                concurrent edits, to help mitigate the problems caused by them. ConE has
                been designed to scale, and to minimize false alarms while still flagging
                relevant concurrently edited files. Key concepts of ConE include the
                detection of the Extent of Overlap between pull requests, and the
                identification of Rarely Concurrently Edited Files. To evaluate ConE, we
                report on its operational deployment on 234 repositories inside Microsoft.
                ConE assessed 26,000 pull requests and made 775 recommendations about
                conflicting changes, which were rated as useful in over 70% (554) of the
                cases. From interviews with 48 users we learned that they believed cone
                would save time in conflict resolution and avoiding duplicate work, and that
                over 90% intend to keep using the service on a daily basis.
                },
  url        = {https://arxiv.org/pdf/2101.06542.pdf}
}

@article{IHG21,
  author   = {Maliheh Izadi and Abbas Heydarnoori and Georgios Gousios},
  title    = {Topic recommendation for software repositories using multi-label classification algorithms},
  journal  = {Empirical Software Engineering},
  volume   = {26},
  number   = {5},
  pages    = {93},
  year     = {2021},
  url      = {https://arxiv.org/pdf/2010.09116},
  doi      = {10.1007/s10664-021-09976-2},
  abstract = {
              Many platforms exploit collaborative tagging to provide their users with
              faster and more accurate results while searching or navigating. Tags can
              communicate different concepts such as the main features, technologies,
              functionality, and the goal of a software repository. Recently, GitHub has
              enabled users to annotate repositories with topic tags. It has also provided
              a set of featured topics, and their possible aliases, carefully curated with
              the help of the community. This creates the opportunity to use this initial
              seed of topics to automatically annotate all remaining repositories, by
              training models that recommend high-quality topic tags to developers. In
              this work, we study the application of multi-label classification techniques
              to predict software repositories' topics. First, we map the large-space of
              user-defined topics to those featured by GitHub. The core idea is to derive
              more information from projects' available documentation. Our data contains
              about 152K GitHub repositories and 228 featured topics. Then, we apply
              supervised models on repositories' textual information such as descriptions,
              README files, wiki pages, and file names. We assess the performance of our
              approach both quantitatively and qualitatively. Our proposed model achieves
              Recall\@5 and LRAP scores of 0.890 and 0.805, respectively. Moreover, based
              on users' assessment, our approach is highly capable of recommending correct
              and complete set of topics. Finally, we use our models to develop an online
              tool named Repository Catalogue, that automatically predicts topics for
              GitHub repositories and is publicly available.
              }
}


@article{BG20,
  author     = {Boldi, Paolo and Gousios, Georgios},
  title      = {Fine-Grained Network Analysis for Modern Software Ecosystems},
  year       = {2020},
  issue_date = {December 2020},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {21},
  number     = {1},
  issn       = {1533-5399},
  doi        = {10.1145/3418209},
  journal    = {ACM Trans. Internet Technol.},
  month      = dec,
  articleno  = {1},
  numpages   = {14},
  keywords   = {security breaches, Software reuse, network analysis},
  abstract   = {
                Modern software development is increasingly dependent on components,
                libraries, and frameworks coming from third-party vendors or open-source
                suppliers and made available through a number of platforms (or forges).
                This way of writing software puts an emphasis on reuse and on
                composition, commoditizing the services that modern applications require.
                On the other hand, bugs and vulnerabilities in a single library living in
                one such ecosystem can affect, directly or by transitivity, a huge number
                of other libraries and applications. Currently, only product-level
                information on library dependencies is used to contain this kind of
                danger, but this knowledge often reveals itself too imprecise to lead to
                effective (and possibly automated) handling policies. We will discuss how
                fine-grained function-level dependencies can greatly improve reliability
                and reduce the impact of vulnerabilities on the whole software ecosystem.
                },
  url        = {https://arxiv.org/pdf/2012.04760.pdf}
}

@article{BGPPAZ17,
  author   = {M. {Beller} and G. {Gousios} and A. {Panichella} and S. {Proksch} and S. {Amann} and A. {Zaidman}},
  journal  = {IEEE Transactions on Software Engineering},
  title    = {Developer Testing in the IDE: Patterns, Beliefs, and Behavior},
  year     = {2019},
  volume   = {45},
  number   = {3},
  pages    = {261-284},
  doi      = {10.1109/TSE.2017.2776152},
  issn     = {0098-5589},
  month    = mar,
  abstract = {
              Software testing is one of the key activities to achieve software quality
              in practice. Despite its importance, however, we have a remarkable lack of
              knowledge on how developers test in real-world projects. In this paper, we
              report on a large-scale field study with 2,443 software engineers whose
              development activities we closely monitored over 2.5 years in four integrated
              development environments (IDEs). Our findings, which largely generalized
              across the studied IDEs and programming languages Java and C#, question
              several commonly shared assumptions and beliefs about developer testing:
              half of the developers in our study do not test; developers rarely run
              their tests in the IDE; most programming sessions end without any test
              execution; only once they start testing, do they do it extensively; a quarter
              of test cases is responsible for three quarters of all test failures; 12
              percent of tests show flaky behavior; Test-Driven Development (TDD) is
              not widely practiced; and software developers only spend a quarter of
              their time engineering tests, whereas they think they test half of their
              time. We summarize these practices of loosely guiding one's development
              efforts with the help of testing in an initial summary on Test-Guided
              Development (TGD), a behavior we argue to be closer to the development
              reality of most developers than TDD.
              },
  url      = {/pub/developer-testing-in-IDE.pdf}
}

@article{CAGDT17,
  author   = {Coelho, Roberta and Almeida, Lucas and Gousios, Georgios and Deursen,
              Arie van and Treude, Christoph},
  title    = {Exception handling bug hazards in Android},
  journal  = {Empirical Software Engineering},
  year     = {2017},
  month    = {Jun},
  day      = {01},
  volume   = {22},
  number   = {3},
  pages    = {1264--1304},
  issn     = {1573-7616},
  doi      = {10.1007/s10664-016-9443-7},
  abstract = {
              Adequate handling of exceptions has proven difficult for many software
              engineers. Mobile app developers in particular, have to cope with
              compatibility, middleware, memory constraints, and battery restrictions.
              The goal of this paper is to obtain a thorough understanding of common
              exception handling bug hazards that app developers face. To that end, we
              first provide a detailed empirical study of over 6,000 Java exception
              stack traces we extracted from over 600 open source Android projects. Key
              insights from this study include common causes for system crashes, and
              common chains of wrappings between checked and unchecked exceptions.
              Furthermore, we provide a survey with 71 developers involved in at least
              one of the projects analyzed. The results corroborate the stack trace
              findings, and indicate that developers are unaware of frequently
              occurring undocumented exception handling behavior. Overall, the findings
              of our study call for tool support to help developers understand their
              own and third party exception handling and wrapping logic.
              },
  url      = {/pub/exception-handling-bug-hazards-android.pdf}
}

@article{KGBSGD16,
  year      = {2016},
  issn      = {1573-7616},
  journal   = {Empirical Software Engineering},
  doi       = {10.1007/s10664-015-9393-5},
  title     = {An in-depth study of the promises and perils of mining {GitHub}},
  publisher = {Springer US},
  keywords  = {Mining software repositories; git; GitHub; Code reviews},
  author    = {Kalliamvakou, Eirini and Gousios, Georgios and Blincoe, Kelly and Singer, Leif and German, DanielM. and Damian, Daniela},
  pages     = {2035--2071},
  volume    = {21},
  number    = {5},
  abstract  = {
               With over 10 million git repositories, GitHub is becoming one of the most
               important sources of software artifacts on the Internet. Researchers mine
               the information stored in GitHub's event logs to understand how its users
               employ the site to collaborate on software, but so far there have been no
               studies describing the quality and properties of the available GitHub
               data. We document the results of an empirical study aimed at
               understanding the characteristics of the repositories and users in
               GitHub; we see how users take advantage of GitHub's main features and how
               their activity is tracked on GitHub and related datasets to point out
               misalignment between the real and mined data. Our results indicate that
               while GitHub is a rich source of data on software development, mining
               GitHub for research purposes should take various potential perils into
               consideration. For example, we show that the majority of the projects are
               personal and inactive, and that almost 40\% of all pull requests do not
               appear as merged even though they were. Also, approximately half of
               GitHub's registered users do not have public activity, while the activity
               of GitHub users in repositories is not always easy to pinpoint. We use
               our identified perils to see if they can pose validity threats; we review
               selected papers from the MSR 2014 Mining Challenge and see if there are
               potential impacts to consider. We provide a set of recommendations for
               software engineering researchers on how to approach the data in GitHub.
               },
  url       = {/pub/promises-perils-github-extended.pdf}
}

@article{GS14,
  year      = {2014},
  issn      = {1382-3256},
  journal   = {Empirical Software Engineering},
  volume    = {19},
  number    = {4},
  doi       = {10.1007/s10664-013-9242-3},
  title     = {Conducting quantitative software engineering studies with Alitheia Core},
  publisher = {Springer US},
  keywords  = {Quantitative software engineering; Software repository mining},
  author    = {Gousios, Georgios and Spinellis, Diomidis},
  pages     = {885-925},
  url       = {/pub/conducting-quantitative-softeng-studies-alitheia-core.pdf},
  abstract  = {
               Quantitative empirical software engineering research benefits mightily
               from processing large open source software repository data sets. The
               diversity of repository management tools and the long history of some
               projects, renders the task of working those datasets a tedious and
               error-prone exercise. The Alitheia Core analysis platform preprocesses
               repository data into an intermediate format that allows researchers to
               provide custom analysis tools. Alitheia Core automatically distributes
               the processing load on multiple processors while enabling programmatic
               access to the raw data, the metadata, and the analysis results. The tool
               has been successfully applied on hundreds of medium to large-sized
               open-source projects, enabling large-scale empirical studies.
               }
}

@article{LG12,
  author    = {Panos Louridas and Georgios Gousios},
  doi       = {10.1145/2347696.2347706},
  issn      = {0163-5948},
  journal   = {SIGSOFT Softw. Eng. Notes},
  month     = sep,
  number    = {5},
  pages     = {1--4},
  publisher = {ACM},
  title     = {A note on rigour and replicability},
  url       = {/pub/note-rigour-replicability.pdf},
  volume    = {37},
  year      = {2012},
  abstract  = {
               As any empirical science, Software Engineering research should strive
               towards better research practices. Replication is regrettably not a
               priority for Software Engineering researchers and, moreover, not afforded
               by many published studies. Here we report our experience from our
               encounter with a recent paper in a flagship Software Engineering
               conference. Our experience shows that current publication requirements do
               not guarantee replicability.
               }
}

@article{ASKG11,
  author   = {Stephanos Androutsellis-Theotokis and Diomidis Spinellis and Maria Kechagia and Georgios Gousios},
  doi      = {10.1561/0200000026},
  issn     = {1571-9545},
  journal  = {Foundations and Trends in Technology, Information and Operations Management},
  number   = {3--4},
  pages    = {187--347},
  title    = {Open Source Software: A Survey from 10,000 Feet},
  url      = {/pub/oos-10000-feet.pdf},
  volume   = {4},
  year     = 2011,
  abstract = {
              Open source software (OSS), the origins of which can be traced back to
              the 1950s, is software distributed with a license that allows access to
              its source code, free redistribution, the creation of derived works, and
              unrestricted use. OSS applications cover most areas of consumer and
              business software and their study touches many disciplines, including
              computer science, information systems, economics, psychology, and law.
              Behind a successful OSS project lies a community of actors, ranging from
              core developers to passive users, held together by a flexible governance
              structure and membership, leadership and contribution policies that align
              their interests. The motivation behind individuals participating in OSS
              projects can be, among others, social, ideological, hedonistic, or
              signaling, while companies gain from their access to high-quality,
              innovative projects and an increase in their reputation and visibility.
              Nowadays many business models rely on OSS as a product through the
              provision of associated services, or in coexistence with proprietary
              software, hardware, services, or licensing. The numerous OSS licenses
              mainly differ on how they treat derived software: some contain provisions
              that maintain its availability in open source form while others allow
              more flexibility. Through its widespread adoption, OSS is affecting the
              software industry, science, engineering, research, teaching, the
              developing countries, and the society at large through its ability to
              democratize technology and innovation.
              }
}

@article{SGKLASS09,
  author   = {Diomidis Spinellis and Georgios Gousios and Vassilios Karakoidas and Panagiotis Louridas and Paul J. Adams and Ioannis Samoladas and Ioannis Stamelos},
  doi      = {10.1016/j.entcs.2009.02.058},
  issn     = {1571-0661},
  journal  = {Electronic Notes in Theoretical Computer Science},
  pages    = {5 -- 28},
  title    = {Evaluating the Quality of Open Source Software},
  url      = {/pub/eval-quality-of-open-source-software.pdf},
  volume   = {233},
  year     = {2009},
  abstract = {
              Traditionally, research on quality attributes was either kept under wraps
              within the organization that performed it, or carried out by outsiders
              using narrow, black-box techniques. The emergence of open source software
              has changed this picture allowing us to evaluate both software products
              and the processes that yield them. Thus, the software source code and the
              associated data stored in the version control system, the bug tracking
              databases, the mailing lists, and the wikis allow us to evaluate quality
              in a transparent way. Even better, the large number of (often competing)
              open source projects makes it possible to contrast the quality of
              comparable systems serving the same domain. Furthermore, by combining
              historical source code snapshots with significant events, such as bug
              discoveries and fixes, we can further dig into the causes and effects of
              problems. Here we present motivating examples, tools, and techniques that
              can be used to evaluate the quality of open source (and by extension also
              proprietary) software.
              }
}

@article{GAG04,
  author   = {Georgios Gousios and Efthimia Aivaloglou and Stefanos Gritzallis},
  journal  = {Computer Standards \& Interfaces},
  month    = {Mar},
  volume   = {27},
  number   = {3},
  pages    = {269--284},
  title    = {Distributed Component Architectures Security Issues},
  url      = {/pub/distributed-component-architectures-security-issues.pdf},
  volume   = 27,
  doi      = {10.1016/j.csi.2004.08.003},
  year     = {2005},
  abstract = {
              Enterprise information systems and e-commerce applications are tightly
              integrated in today ’s modern enterprises. Component architectures are
              the base for building such multi-tier, distributed applications. This
              paper examines the security threats those systems must confront and the
              solutions proposed by the major existing component architectures. A
              comparative evaluation of both security features and implementation
              issues is carried out to determine each architecture’s strong points and
              drawbacks.
              }
}