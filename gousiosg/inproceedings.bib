@inproceedings{BMG18,
author = {Banken, Herman and Meijer, Erik and Gousios, Georgios},
 title = {Debugging Data Flows in Reactive Programs},
 booktitle = {Proceedings of the 40th International Conference on Software Engineering},
 series = {ICSE '18},
 year = {2018},
 isbn = {978-1-4503-5638-1},
 location = {Gothenburg, Sweden},
 pages = {752--763},
 numpages = {12},
 doi = {10.1145/3180155.3180156},
 acmid = {3180156},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {debugging, program comprehension, reactive programming, visualization},
  Abstract = {

  Reactive Programming is a style of programming that provides developers with a
  set of abstractions that facilitate event handling and stream processing.
  Traditional debug tools lack support for Reactive Programming, leading
  developers to fallback to the most rudimentary debug tool available: logging
  to the console.

  In this paper, we present the design and implementation of RxFiddle, a
  visualization and debugging tool targeted to Rx, the most popular form of
  Reactive Programming. RxFiddle visualizes the dependencies and structure of
  the data flow, as well as the data inside the flow. We evaluate RxFiddle with
  an experiment involving 111 developers. The results show that RxFiddle can
  help developers finish debugging tasks faster than with traditional debugging
  tools.

  },
  url = {/pub/debugging-dataflows-in-reactive-programs.pdf},
  github = {hermanbanken/RxFiddle}
}

@inproceedings{BHVG18,
  author = {Eduard Van der Bent and Jurriaan Hage and Joost Visser and Georgios Gousios},
  title = {How Good Is Your Puppet? An Empirically Defined and Validated Quality Model for Puppet},
  booktitle = {Proceedings of the 25th IEEE International Conference on Software Analysis, Evolution and Reengineering},
  series = {SANER 2018},
  year = {2018},
  location = {Campobasso, Italy},
  numpages = {11},
  abstract = {

  Puppet is a declarative language for configuration management that has rapidly
  gained popularity in recent years. Numerous organizations now rely on Puppet
  code for deploying their software systems onto cloud infrastructures. In this
  paper we provide a definition of code quality for Puppet code and an automated
  technique for measuring and rating Puppet code quality. To this end, we first
  explore the notion of code quality as it applies to Puppet code by performing
  a survey among Puppet developers. Second, we develop a measurement model for
  the maintainability aspect of Puppet code quality. To arrive at this
  measurement model, we derive appropriate quality metrics from our survey
  results and from existing software quality models. We implemented the Puppet
  code quality model in a software analysis tool. We validate our definition of
  Puppet code quality and the measurement model by a structured interview with
  Puppet experts and by comparing the tool results with quality judgments of
  those experts. The validation shows that the measurement model and tool
  provide quality judgments of Puppet code that closely match the judgments of
  experts. Also, the experts deem the model appropriate and usable in practice.
  The Software Improvement Group (SIG) has started using the model in its
  consultancy practice.

  },
  url = {/pub/how-good-is-your-puppet.pdf},
}

@inproceedings{KGDP17,
  author = {Riivo Kikas and Georgios Gousios and Marlon Dumas and Dietmar Pfahl},
  title = {Structure and Evolution of Package Dependency Networks},
  booktitle = {Proceedings of the 14th Working Conference on Mining Software Repositories},
  year = {2017},
  month = {May},
  location = {Buenos Aires, Argentina},
  series = {MSR '17},
  publisher = {IEEE press},
  pages = {102--112},
  doi = {10.1109/MSR.2017.55},
  Abstract = {

  Software developers often include available open-source software packages into
    their projects to minimize redundant effort. However, adding a package to a
    project can also introduce risks, which can propagate through multiple
    levels of dependencies. Currently, not much is known about the structure of
    open-source package ecosystems of popular programming languages and the
    extent to which transitive bug propagation is possible. This paper analyzes
    the dependency network structure and evolution of the JavaScript, Ruby, and
    Rust ecosystems. The reported results reveal significant differences across
    language ecosystems. The results indicate that the number of transitive
    dependencies for JavaScript has grown 60\% over the last year, suggesting
    that developers should look more carefully into their dependencies to
    understand what exactly is included. The study also reveals that
    vulnerability to a removal of the most popular package is increasing, yet
    most other packages have a decreasing impact on vulnerability. The findings
    of this study can inform the development of dependency management tools.

  },
  github = {riivo/package-dependency-networks},
  url = {/pub/ecosystems-evolution.pdf},
  speakerdeck = {a0d2f40f871941c6b1cf993b71e5af09}
}

@inproceedings{BGZ17,
 author = {Moritz Beller and Georgios Gousios and Andy Zaidman},
 title = {Oops, My Tests Broke the Build: An Explorative Analysis of Travis CI with GitHub},
 booktitle = {Proceedings of the 14th Working Conference on Mining Software Repositories},
 series = {MSR'17},
 year = {2017},
 publisher = {IEEE press},
 pages = {356--367},
 doi = {10.1109/MSR.2017.62},
 location = {Buenos Aires, Argentina},
 url = {/pub/tests-broke-build-explorative-analysis-travis-ci-github.pdf},
 Abstract = {

  Continuous Integration (CI) has become a best practice of modern software
    development. Yet, at present, we have a shortfall of insight into the
    testing practices that are common in CI-based software development. In
    particular, we seek quantifiable evidence on how central testing is to the
    CI process, how strongly the project language influences testing, whether
    different integration environ- ments are valuable and if testing on the CI
    can serve as a surrogate to local testing in the IDE. In an analysis of
    2,640,825 Java and Ruby builds on Travis CI, we find that testing is the
    single most important reason why builds fail. Moreover, the programming lan-
    guage has a strong influence on both the number of executed tests, their run
    time, and proneness to fail. The use of multiple integra- tion environments
    leads to 10\% more failures being caught at build time. However, testing on
    Travis CI does not seem an adequate surrogate for running tests locally in
    the IDE. To further research on Travis CI with GitHub, we introduce
    Travistorrent.
 }
}

@inproceedings{GSB16,
  author = {Georgios Gousios and Margaret-Anne Storey and
  Alberto Bacchelli},
  title = {Work Practices and Challenges in Pull-Based Development: The Contributor's Perspective},
  booktitle = {Proceedings of the 38th International Conference on Software Engineering},
  year = {2016},
  month = {May},
  location = {Austin, Texas},
  series = {ICSE '16},
  isbn = {978-1-4503-3900-1},
  publisher = {ACM},
  pages = {285--296},
  Abstract = {
  The pull-based development model is an emerging way of contributing to
  distributed software projects that is gaining enormous popularity within the
  open source software (OSS) world. Previous work has examined this model by
  focusing on projects and their owners---we complement it by examining the
  work practices of project contributors and the challenges they face.

  We conducted a survey with 645 top contributors to active OSS projects using
  the pull-based model on GitHub, the prevalent social coding site. We also
  analyzed traces extracted from corresponding GitHub repositories.

 Our research shows that: contributors have a strong interest in maintaining
 awareness of project status to get inspiration and avoid duplicating work, but
 they do not actively propagate information; communication within pull requests
 is reportedly limited to low-level concerns and contributors often use
 communication channels external to pull requests; challenges are mostly social
 in nature, with most reporting poor responsiveness from integrators; and the
 increased transparency of this setting is a confirmed motivation to contribute.

 Based on these findings, we present recommendations for practitioners to
 streamline the contribution process and discuss potential future research
 directions.},
  doi = {10.1145/2884781.2884826},
  award = {ACM SIGSOFT Distinguished paper},
  speakerdeck = {b24994c612524f0e959565281bf9cd8f},
  github = {gousiosg/pullreqs-contributors},
  url={/pub/pullreqs-contributors.pdf}
}

@inproceedings{BGPZ15,
  author = {Beller, Moritz and Gousios, Georgios and Panichella, Annibale and Zaidman, Andy},
  title = {When, How, and Why Developers (Do Not) Test in Their IDEs},
  booktitle = {Proceedings of the 10th Joint Meeting on Foundations of Software Engineering},
  series = {ESEC/FSE 2015},
  year = {2015},
  isbn = {978-1-4503-3675-8},
  location = {Bergamo, Italy},
  pages = {179--190},
  doi = {10.1145/2786805.2786843},
  acmid = {2786843},
  publisher = {ACM},
  address = {New York, NY, USA},
  Abstract = {
    The research community in Software Engineering and Software Testing in
    particular builds many of its contributions on a set of mutually shared
    expectations. These expectations often form the motivation for research on
    the creation of new testing tools and the refinement of existing test
    processes in an attempt to support practitioners. Despite the fact that they
    are the basis for many publications as well as open-source and commercial
    testing applications, the common expectations and beliefs are rarely ever
    questioned.  For example, Frederic Brooks' statement that testing takes half
    of the development time seems to have manifested itself within the community
    since he first made it in the ``Mythical Man Month'' in 1975. With this
    paper, we report on the surprising results of a large-scale field study with
    416 software engineers whose development activity we closely monitored over
    the course of five months, resulting in over 13 years of recorded work time.
    Our findings question several commonly shared assumptions and beliefs about
    testing and might be contributing factors to the observed bug proneness of
    software in practice: the majority of developers in our study does not test;
    developers rarely run their tests in the IDE; Test-driven Development is not
    widely practiced; and, last but not least, software developers only spend a
    quarter of their work time engineering tests, whereas they think they test
    half of their time.
  },
   url = {/pub/when-how-why-developers-do-not-test.pdf}
}

@inproceedings{GZSD15,
  author = {Georgios Gousios and Andy Zaidman and Margaret-Anne Storey and Arie van Deursen},
  title = {Work Practices and Challenges in Pull-Based Development: The
    Integrator's Perspective},
  booktitle = {Proceedings of the 37th International Conference on Software Engineering},
  series = {ICSE},
  year = {2015},
  month = {May},
  volume={1},
  pages={358-368},
  location = {Florence, Italy},
  doi = {10.1109/ICSE.2015.55},
  Abstract = {
    In the pull-based development model, the integrator has the crucial role of
    managing and integrating contributions. This work focuses on the role of
    the integrator and investigates working habits and challenges alike. We set
    up an exploratory qualitative study involving a large-scale survey of 749
    integrators, to which we add quantitative data from the integrator's
    project.  Our results provide insights into the factors they consider in
    their decision making process to accept or reject a contribution. Our key
    findings are that integrators struggle to maintain the quality of their
    projects and have difficulties with prioritizing contributions that are to
    be merged.  Our insights have implications for practitioners who wish to
    use or improve their pull-based development process, as well as for
    researchers striving to understand the theoretical implications of the
    pull-based model in software development.},
  url = {/pub/pullreqs-integrators.pdf},
  github = {gousiosg/pullreqs-integrators},
  speakerdeck = "e340d9f98bd0426abada24888cf6f32d"
}

@inproceedings{CAGD15,
  author = {Roberta Coelho and Lucas Almeida and Georgios Gousios and Arie van
  Deursen},
  title = {Unveiling Exception Handling Bug Hazards in Android based on GitHub and Google Code Issues},
  booktitle = {Proceedings of the 2015 IEEE/ACM 12th Working Conference on Mining Software Repositories (MSR)},
  year = {2015},
  month={May},
  location = {Florence, Italy},
  Abstract = {
    This paper reports on a study mining the exception stack traces included in
    159,048 issues reported on Android projects hosted in GitHub (482 projects)
    and Google Code (157 projects). The goal of this study is to investigate
    whether stack trace information can reveal bug hazards related to exception
    handling code that may lead to a decrease in application robustness. Overall
    6,005 exception stack traces were extracted, and subjected to source code
    and bytecode analysis. The outcomes of this study include the identification
    of the following bug hazards: (i) unexpected cross-type exception wrappings
    (for instance, trying to handle an instance of OutOfMemoryError ``hidden''
    in a checked exception) which can make the exception-related code more
    complex and negatively impact the application robustness; (ii) undocumented
    runtime exceptions thrown by both the Android platform and third party
    libraries; and (iii) undoc- umented checked exceptions thrown by the Android
    Platform. Such undocumented exceptions make difficult, and most of the times
    infeasible for the client code to protect against unforeseen situations that
    may happen while calling third-party code. This study provides further
    insights on such bug hazards and the robustness threats they impose to
    Android apps as well as to other systems based on the Java exception model.
   },
  pages={134-145},
  doi={10.1109/MSR.2015.20},
  url = {/pub/android-stacks.pdf},
  github = {gousiosg/java-stacktrace-analysis},
  speakerdeck="24731ec0a49f4724a82dd7b9e1f870f3"
}

@inproceedings{HGD15,
  author = {Hennie Huijgens and Georgios Gousios and Arie van Deursen},
  title = {Pricing via Functional Size: A Case Study of a Company's Portfolio of 77 Outsourced Projects},
  booktitle = {2015 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
  year = {2015},
  pages = {1--10},
  location = {Beijing, China},
  doi = {10.1109/ESEM.2015.7321211},
  month = "Oct",
  Abstract = {
  A medium-sized west-European telecom company experienced a worsening trend in
  performance, indicating that the organization did not learn from history, in
  combination with much time and energy spent on preparation and review of
  project proposals. In order to create more transparency in the supplier
  proposal process a pilot was started on Functional Size Measurement pricing
  (FSM-pricing). In this paper, we evaluate the implementation of FSM-pricing
  in the software engineering domain of the company, as an instrument useful in
  the context of software man- agement and supplier proposal pricing. We found
  that a statistical, evidence-based pricing approach for software engineering,
  as a single instrument (without a connection with expert judgment), can be
  used in the subject companies to create cost transparency and performance
  management of software project portfolios.},
  url = {/pub/pricing-via-functional-size.pdf}
}

@inproceedings{DBGCD15,
  author = {Martin Dias and Alberto Bacchelli and Georgios Gousios and Damien Cassou and Stephane Ducasse},
  title = {Untangling Fine-Grained Code Changes},
  booktitle = {Proceedings of the 22nd IEEE International Conference on Software Analysis, Evolution, and Reengineering},
  series = {SANER 2015},
  year = {2015},
  location = {Montreal, Canada},
  pages = {341--350},
  doi = {10.1109/SANER.2015.7081844},
  Abstract = {
    After working for some time, developers commit their code changes to a
    version control system. When doing so, research shows that they often bundle
    unrelated changes (e.g., bug fix and refactoring) in a single commit, thus
    creating a so-called tangled commit. Sharing tangled commits is problematic
    because it makes review, reversion, and integration of these commits harder
    and historical analyses of the project less reliable.  Researchers have
    worked at untangling existing commits, i.e., finding which part of a commit
    relates to which task. In this paper, we contribute to this line of work in
    two ways: (1) A publicly available dataset of untangled code changes,
    created with the help of two developers who accurately split their code
    changes into self contained tasks over a period of four months; (2) based on
    this dataset we devise and assess EpiceaUntangler, an approach to help
    developers share untangled commits (aka. atomic commits) by using
    fine-grained code change information. We further evaluate EpiceaUntangler by
    deploying it to 7 developers, who used it for 2 weeks. We recorded a median
    success rate of 91\% and average one of 75\%, in automatically creating
    clusters of untangled fine-grained code changes.
  },
  url = {/pub/fine-untangling.pdf},
  nomination = {SANER best paper}
}

@inproceedings{GPD14,
  author = {Gousios, Georgios and Pinzger, Martin and Deursen, Arie van},
  title = {An Exploratory Study of the Pull-based Software Development Model},
  booktitle = {Proceedings of the 36th International Conference on Software Engineering},
  Year = {2014},
  series = {ICSE},
  isbn = {978-1-4503-2756-5},
  location = {Hyderabad, India},
  pages = {345--355},
  numpages = {11},
  doi = {10.1145/2568225.2568260},
  acmid = {2568260},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {Pull-based development, distributed software development, empirical software engineering, pull request},
  Abstract = {
    The advent of distributed version control systems has led to the development
    of a new paradigm for distributed software development; instead of pushing
    changes to a central repository, developers pull them from other
    repositories and merge them locally. Various code hosting sites, notably
    Github, have tapped on the opportunity to facilitate pull-based development
    by offering workflow support tools, such as code reviewing systems and
    integrated issue trackers. In this work, we explore how pull-based software
    development works, first on the GHTorrent corpus and then on a carefully
    selected sample of 291 projects. We find that the pull request model offers
    fast turnaround, increased opportunities for community engagement and
    decreased time to incorporate contributions. We show that a relatively small
    number of factors affect both the decision to merge a pull request and the
    time to process it.  We also examine the reasons for pull request rejection
    and find that technical ones are only a small minority.
  },
  speakerdeck = "2c6de050ce430131e1db2aa9d004a740",
  url = {/pub/exploration-pullreqs.pdf},
  nomination = {ACM SIGSOFT distinguished paper},
  github = {gousiosg/pullreqs}
}

@inproceedings{KGBSGD14,
  author = {Kalliamvakou, Eirini and Gousios, Georgios and Blincoe, Kelly and Singer, Leif and German, Daniel M. and Damian, Daniela},
  title = {The Promises and Perils of Mining GitHub},
  booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
  series = {MSR 2014},
  year = {2014},
  isbn = {978-1-4503-2863-0},
  location = {Hyderabad, India},
  pages = {92--101},
  numpages = {10},
  doi = {10.1145/2597073.2597074},
  acmid = {2597074},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {Mining software repositories, bias, code reviews, git, github},
  Abstract = {
    With over 10 million Git repositories, GitHub is becoming one of the most
    important source of software artifacts on the Internet. Researchers are
    starting to mine the information stored in GitHub's event logs, trying to
    understand how its users employ the site to collaborate on software.
    However, so far there have been no studies describing the quality and
    properties of the data available from GitHub. We document the results of an
    empirical study aimed at understanding the characteristics of the
    repositories in GitHub and how users take advantage of GitHub's main
    features---namely commits, pull requests, and issues. Our results indicate
    that, while GitHub is a rich source of data on software development, mining
    GitHub for research purposes should take various potential perils into
    consideration. We show, for example, that the majority of the projects are
    personal and inactive; that GitHub is also being used for free storage and
    as a Web hosting service; and that almost 40\% of all pull requests do not
    appear as merged, even though they were. We provide a set of recommendations
    for software engineering researchers on how to approach the data in GitHub.},
  url = {/pub/promises-perils-github.pdf},
}

@inproceedings{G13,
  Author = {Georgios Gousios},
  Title = {The {GHT}orrent dataset and tool suite},
  Year = 2013,
  Month = May,
  pages = {233--236},
  numpages = {4},
  Booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
  series = {MSR '13},
  isbn = {978-1-4673-2936-1},
  location = {San Francisco, CA, USA},
  abstract = {
    A common requirement of many empirical software engineering studies is the
    acquisition and curation of data from software repositories. During the last
    few years, GitHub has emerged as a popular project hosting, mirroring and
    collaboration platform. GitHub provides an extensive REST API, which enables
    researchers to retrieve both the commits to the projects’ repositories and
    events generated through user actions on project resources. GHTorrent aims
    to create a scalable off line mirror of GitHub’s event streams and
    persistent data, and offer it to the research community as a service. In
    this paper, we present the project’s design and initial implementation and
    demonstrate how the provided datasets can be queried and processed.
  },
  url = {/pub/ghtorrent-dataset-toolsuite.pdf},
  github = {gousiosg/github-mirror},
  speakerdeck = "75bea5909fbb0130f0eb364613f6f036",
  award = {MSR2013: Best data showcase paper},
  Note = {Best data showcase paper award}
}

@inproceedings{GS12,
  Author = {Georgios Gousios and Diomidis Spinellis},
  Booktitle = { {MSR} '12: Proceedings of the 9th Working Conference on Mining Software Repositories},
  Editor = {Michael W. Godfrey and Jim Whitehead},
  Location = {Zurich, Switzerland},
  Month = jun,
  Pages = {12--21},
  Publisher = {IEEE},
  Title = { {GHT}orrent: {G}it{H}ub's Data from a Firehose},
  Year = 2012,
  doi = {10.1109/MSR.2012.6224294},
  ISSN = {2160-1852},
  SlideshareEmbed = "13184524",
  abstract = {
    A common requirement of many empirical software engineering studies is the
    acquisition and curation of data from software repositories. During the last
    few years, GitHub has emerged as a popular project hosting, mirroring and
    collaboration platform. GitHub provides an extensive REST API, which enables
    researchers to retrieve both the commits to the projects’ repositories and
    events generated through user actions on project resources. GHTorrent aims
    to create a scalable off line mirror of GitHub’s event streams and
    persistent data, and offer it to the research community as a service. In
    this paper, we present the project’s design and initial implementation and
    demonstrate how the provided datasets can be queried and processed.
    },
  url = {/pub/ghtorrent-githubs-data-from-a-firehose.pdf},
  github = {gousiosg/github-mirror}
}

@inproceedings{GS09b,
  Author = {Georgios Gousios and Diomidis Spinellis},
  Booktitle = { {MSR} '09: Proceedings of the 6th Working Conference on Mining Software Repositories},
  Day = {16--17},
  Editor = {Michael W. Godfrey and Jim Whitehead},
  Isbn = {978-1-4244-3493-0},
  Location = {Vancouver, Canada},
  Month = may,
  Pages = {31--40},
  Publisher = {IEEE},
  Title = {A platform for software engineering research},
  doi={10.1109/MSR.2009.5069478},
  Year = 2009,
  abstract = {
    Research in the fields of software quality, maintainabil- ity and evolution
    requires the analysis of large quantities of data, which often originate
    from open source software projects. Collecting and preprocessing data,
    calculating metrics, and synthesizing composite results from a large corpus
    of project artifacts is a tedious and error prone task lacking direct
    scientific value. The Alitheia Core tool is an extensible platform for
    software quality analysis that is designed specifically to facilitate
    software engineering research on large and diverse data sources, by
    integrating data collection and preprocessing phases with an array of
    analysis services, and presenting the researcher with an easy to use
    extension mechanism. Alitheia Core aims to be the basis of an ecosystem of
    shared tools and research data that will enable researchers to focus on
    their research questions at hand, rather than spend time on re-implementing
    analysis tools.

    In this paper, we present the Alitheia Core platform in detail and
    demonstrate its usefulness in mining software repositories by guiding the
    reader through the steps required to execute a simple experiment.
  },
  url = {/pub/a-platform-for-software-engineering-research.pdf},
  github = {istlab/Alitheia-Core}
}

@inproceedings{SGSS08,
  Address = {Boston},
  Author = {Ioannis Samoladas and Georgios Gousios and Diomidis Spinellis and Ioannis Stamelos},
  Editor = {Ernesto Damiani and Giancarlo Succi},
  Location = {Milan, Italy},
  Month = {Sep},
  Organization = {IFIP 20th World Computer Congress, Working Group 2.3 on Open Source Software},
  Pages = {237--248},
  Publisher = {Springer},
  Title = {The {SQO-OSS} Quality Model: Measurement Based Open Source Software Evaluation},
  booktitle={Open Source Development, Communities and Quality},
  volume={275},
  pages={237-248},
  doi={10.1007/978-0-387-09684-1_19},
  Year = {2008},
  abstract = {
    Software quality evaluation has always been an important part of software
    business. The quality evaluation process is usually based on hierarchical
    quality models that measure various aspects of software quality and deduce a
    characterization of the product quality being evaluated. The particular
    nature of open source software has rendered existing models unsuitable for
    detailed quality evaluations. In this paper, we present a hierarchical
    quality model that evaluates source code and community processes, based on
    automatic calculation of metric values and correlation of those to a set of
    predefined quality profiles.
  },
  url = {/pub/sqo-oss-quality-model-measurement-based-open-source-software-evaluation.pdf}
}

@inproceedings{G07,
  Author = {Georgios Gousios},
  Booktitle = {Companion to the 22nd ACM SIGPLAN conference on Object-oriented programming systems, languages, and applications (OOPSLA)},
  Location = {Montreal, Canada},
  Month = {Oct},
  Title = {The {J}ikes{X}en {J}ava Server Platform},
  doi = {10.1145/1297846.1297959},
  pages = {947--948},
  Year = {2007},
  url = {/pub/jikesxen.pdf},
  abstract = {
    The purpose of the JVM is to abstract the Java language from the hardware
    and software platforms it runs on. For this rea- son, the JVM uses services
    offered by the host operating sys- tem in order to implement identical
    services for the Java lan- guage. The obvious duplication of effort in
    service provision and resource management between the JVM and the operat-
    ing system has a measurable cost on the performance of Java programs. In my
    PhD research, I try to find ways of min- imizing the cost of sharing
    resources between the OS and the JVM, by identifying and removing
    unnecessary software layers.}
}

@inproceedings{GKS06,
  Author = {Georgios Gousios and Vassilios Karakoidas and Diomidis Spinellis},
  Booktitle = {Proceedings of the 5th International System Administration and Network Engineering Conference SANE 06},
  Day = {18--19},
  Editor = {Alexios Zavras},
  Location = {Delft, The Netherlands},
  Month = may,
  Organization = {NLUUG},
  Pages = {69--83},
  Publisher = {Stichting SANE},
  Title = {Tuning {J}ava's memory manager for high performance server applications},
  Year = {2006},
  Url = {/pub/paper.pdf},
  abstract = {
    Java is a strong player in the application server market and thus the
    performance of its virtual machine is an important aspect of a server's
    performance. One of the components that affect the performance of a {\sc
    jvm} is the memory manager, which also includes the garbage collector.
    Modern virtual machines offer a multitude of options for tuning the memory
    manager, which can have a significant impact on server application
    performance.

    In this paper, we examine the effect of tuning the garbage collection in an
    application server environment. By employing both synthetic and real world
    application benchmarks, we assess the various garbage collection strategies
    offered by two popular virtual machines. Finally, we present a comprehensive
    list of generally applicable garbage collection guidelines.
  }
}

@inproceedings{GS02,
  Author = {Georgios Gousios and Diomidis Spinellis},
  Booktitle = {Proceedings of the 3rd International System Administration and Networking Conference {SANE 2002}},
  Location = {Maastricht, The Netherlands},
  Month = may,
  Note = {Best refereed paper award},
  Pages = {103--119},
  Title = {A Comparison of Portable Dynamic Web Content Technologies for the Apache Web Server},
  Year = 2002,
  award = {SANE2002: Best refereed paper award},
  url = {/pub/comparison-of-portable-dynamic-web-content-technology-apache.pdf}
}
